{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "34c5ffdaacb848d7a994a21b3459647c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e1a256622da44069b49645a8a32bf00",
              "IPY_MODEL_7dddb268dc3f49b1874c04f8a1066812",
              "IPY_MODEL_b61db242349a47a696ae95c25e241896"
            ],
            "layout": "IPY_MODEL_f28d6db483be46b99c4ce8240193af98"
          }
        },
        "8e1a256622da44069b49645a8a32bf00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93595c8b81d44293aaa2813b2528dacf",
            "placeholder": "​",
            "style": "IPY_MODEL_e4f1f02260074ac19973e29592dc8c7e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "7dddb268dc3f49b1874c04f8a1066812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b25aae87db847eebf7d9abfd756acc6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ec5aed95898438380eb362ad8dd1b03",
            "value": 2
          }
        },
        "b61db242349a47a696ae95c25e241896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcddee2109dc4bd383716d1d999edbc8",
            "placeholder": "​",
            "style": "IPY_MODEL_0cc3bf8a4a714054a1adfcc59e4c9ed8",
            "value": " 2/2 [00:42&lt;00:00, 19.13s/it]"
          }
        },
        "f28d6db483be46b99c4ce8240193af98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93595c8b81d44293aaa2813b2528dacf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4f1f02260074ac19973e29592dc8c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b25aae87db847eebf7d9abfd756acc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ec5aed95898438380eb362ad8dd1b03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dcddee2109dc4bd383716d1d999edbc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cc3bf8a4a714054a1adfcc59e4c9ed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "442d1a063f15462bacee2401e076d0bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd7fd57c86094a1399fda00cfa04b6dd",
              "IPY_MODEL_93596463179e4a75bb127e4da2efd47c",
              "IPY_MODEL_7eddf9a942314028a847cc998a426919"
            ],
            "layout": "IPY_MODEL_d92ec5bed21346abace37c39dd68fc35"
          }
        },
        "cd7fd57c86094a1399fda00cfa04b6dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07635f3d2663480d84e85fee49bc6c53",
            "placeholder": "​",
            "style": "IPY_MODEL_a1d98b09914a4a3290e06c68008e2400",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "93596463179e4a75bb127e4da2efd47c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_296bfd5fd1164d6b9b3bd8c0f894c0c6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a999d420679411b903fde6b86d366e8",
            "value": 2
          }
        },
        "7eddf9a942314028a847cc998a426919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34eae9077b944a478576bf1ec8795a88",
            "placeholder": "​",
            "style": "IPY_MODEL_c1e11fab36404d078e6f04c6652ff163",
            "value": " 2/2 [00:44&lt;00:00, 19.86s/it]"
          }
        },
        "d92ec5bed21346abace37c39dd68fc35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07635f3d2663480d84e85fee49bc6c53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1d98b09914a4a3290e06c68008e2400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "296bfd5fd1164d6b9b3bd8c0f894c0c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a999d420679411b903fde6b86d366e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34eae9077b944a478576bf1ec8795a88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1e11fab36404d078e6f04c6652ff163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86a7b57356454530933052ae5f44253d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_157ca5df468f49d7b1b130161d43960d",
              "IPY_MODEL_2986ebe2dc7e43aa9d081ed164c480b9",
              "IPY_MODEL_7e8bdecf1d0b41ad882f2c27c74933fd"
            ],
            "layout": "IPY_MODEL_174e7b02ee9f4d349c3b0bc12e9134f1"
          }
        },
        "157ca5df468f49d7b1b130161d43960d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_877e548f3f5c4b8688a8acba05852002",
            "placeholder": "​",
            "style": "IPY_MODEL_76fb21af620e45bc8f5b5a9ee117618e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "2986ebe2dc7e43aa9d081ed164c480b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dd1a34b38e947d08f20ba12d2813176",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a4203f2239b410181759350c086cd98",
            "value": 2
          }
        },
        "7e8bdecf1d0b41ad882f2c27c74933fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c282887d7a094dcba80b7610c6eede3e",
            "placeholder": "​",
            "style": "IPY_MODEL_aa80a7c82e56471692255847c27150f2",
            "value": " 2/2 [00:42&lt;00:00, 19.32s/it]"
          }
        },
        "174e7b02ee9f4d349c3b0bc12e9134f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "877e548f3f5c4b8688a8acba05852002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76fb21af620e45bc8f5b5a9ee117618e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dd1a34b38e947d08f20ba12d2813176": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a4203f2239b410181759350c086cd98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c282887d7a094dcba80b7610c6eede3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa80a7c82e56471692255847c27150f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8145391460f342b8a64be170a4f8b989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4005004dff0643c694056e1de3818fca",
              "IPY_MODEL_5d900adf6d4949a0b4351d5c3ab7d368",
              "IPY_MODEL_adcb80c474bd4ee6b3f833dec4971e1f"
            ],
            "layout": "IPY_MODEL_ca4a16b9da524696b209668a7178dde4"
          }
        },
        "4005004dff0643c694056e1de3818fca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c24651e8af64fee9168eaff5d91efb1",
            "placeholder": "​",
            "style": "IPY_MODEL_f396b5f738284e5db9fb45d6af8df42c",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "5d900adf6d4949a0b4351d5c3ab7d368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_690846bd52354029a5ed6e80f3b087a9",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_863eae13f6684cd5aaf01bec78ed392f",
            "value": 2
          }
        },
        "adcb80c474bd4ee6b3f833dec4971e1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93bcccaeddd14c388831835008df1816",
            "placeholder": "​",
            "style": "IPY_MODEL_d29092da064c4cfb8d1ff2a68a52d235",
            "value": " 2/2 [00:40&lt;00:00, 18.47s/it]"
          }
        },
        "ca4a16b9da524696b209668a7178dde4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c24651e8af64fee9168eaff5d91efb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f396b5f738284e5db9fb45d6af8df42c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "690846bd52354029a5ed6e80f3b087a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "863eae13f6684cd5aaf01bec78ed392f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93bcccaeddd14c388831835008df1816": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d29092da064c4cfb8d1ff2a68a52d235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc9eb13f92b8433cb055b3e4b5ce1fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cb679a86b614b0ea946ef0c7db67f41",
              "IPY_MODEL_3ee4732a5e904a5eaccfd3aa87d3e0f2",
              "IPY_MODEL_0d963fa80af24e3784fd739ebd3ca735"
            ],
            "layout": "IPY_MODEL_db4e54c001134fbea91066cb3d7e8c26"
          }
        },
        "4cb679a86b614b0ea946ef0c7db67f41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b6486ad2a3548b5aaab4a227ebd0a39",
            "placeholder": "​",
            "style": "IPY_MODEL_d76c4cb6dd354a20924afe0707341553",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "3ee4732a5e904a5eaccfd3aa87d3e0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aab997b84ab24a2abb5c307418c3189c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cdecc071b24041e2b31fb37b5736e6aa",
            "value": 2
          }
        },
        "0d963fa80af24e3784fd739ebd3ca735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06f1ef20c33e435c877747e618f6160b",
            "placeholder": "​",
            "style": "IPY_MODEL_eeb91e2e53b8448196abcbbe2e9cb4ed",
            "value": " 2/2 [00:41&lt;00:00, 18.52s/it]"
          }
        },
        "db4e54c001134fbea91066cb3d7e8c26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b6486ad2a3548b5aaab4a227ebd0a39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d76c4cb6dd354a20924afe0707341553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aab997b84ab24a2abb5c307418c3189c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdecc071b24041e2b31fb37b5736e6aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06f1ef20c33e435c877747e618f6160b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeb91e2e53b8448196abcbbe2e9cb4ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0dfa05c1fa6d4958898e0e46d21591e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cdcb2ed66a284ccd8106e5cea0c61ac8",
              "IPY_MODEL_39cf7bc34246475c81278cf1ae4c7bea",
              "IPY_MODEL_99f90d9b07634363a0cbd48a671dc2b6"
            ],
            "layout": "IPY_MODEL_953cb7f2c61b4657a9d56310891145e7"
          }
        },
        "cdcb2ed66a284ccd8106e5cea0c61ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebbd8fcbe45c44229bf0880d4b4cbd70",
            "placeholder": "​",
            "style": "IPY_MODEL_935b8777ec484f5ab355cfc6212f39dd",
            "value": "Batches: 100%"
          }
        },
        "39cf7bc34246475c81278cf1ae4c7bea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d426c49d26343ec8235b224eb7599ae",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a24b6dcc63bb4c3db78d10cca6709a1d",
            "value": 1
          }
        },
        "99f90d9b07634363a0cbd48a671dc2b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_566e0647edea4b108bc10af07cc48ca2",
            "placeholder": "​",
            "style": "IPY_MODEL_58d3db21a70c48ff8981cc9471d1a22a",
            "value": " 1/1 [00:16&lt;00:00, 16.12s/it]"
          }
        },
        "953cb7f2c61b4657a9d56310891145e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebbd8fcbe45c44229bf0880d4b4cbd70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "935b8777ec484f5ab355cfc6212f39dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d426c49d26343ec8235b224eb7599ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a24b6dcc63bb4c3db78d10cca6709a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "566e0647edea4b108bc10af07cc48ca2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58d3db21a70c48ff8981cc9471d1a22a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f063dc6867b4c2bb73796d6484d980e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1be486dad9942dda0c269e5fc3fb8ce",
              "IPY_MODEL_307e0967f85d47e88811d3fe76f9dcc1",
              "IPY_MODEL_7a7348d854f6458aab2c3cd9ba437657"
            ],
            "layout": "IPY_MODEL_fc09df23c2364ed48427f20cdb581ef8"
          }
        },
        "a1be486dad9942dda0c269e5fc3fb8ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e93ad8054d45498a9faf1c5f5f5b3396",
            "placeholder": "​",
            "style": "IPY_MODEL_6853fb995be746b68ac85e8607e28ecc",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "307e0967f85d47e88811d3fe76f9dcc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad7e94ccc3864e62961ca39df29c4af2",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfd2a42d2cf0436a87b34fbf3c99c607",
            "value": 2
          }
        },
        "7a7348d854f6458aab2c3cd9ba437657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6978093ec3f24caeb343c280dc5e10be",
            "placeholder": "​",
            "style": "IPY_MODEL_83a94e045a4c44f9be97117f6890e7a4",
            "value": " 2/2 [00:46&lt;00:00, 21.49s/it]"
          }
        },
        "fc09df23c2364ed48427f20cdb581ef8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e93ad8054d45498a9faf1c5f5f5b3396": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6853fb995be746b68ac85e8607e28ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad7e94ccc3864e62961ca39df29c4af2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfd2a42d2cf0436a87b34fbf3c99c607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6978093ec3f24caeb343c280dc5e10be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83a94e045a4c44f9be97117f6890e7a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d52eccb2d4cd4d8ea865da9921913ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dfe5d11e9ad14ddf93e33b49906496aa",
              "IPY_MODEL_11c96697459447f1bb57f4320e343583",
              "IPY_MODEL_5059da18f88d42329967ce7055637a7b"
            ],
            "layout": "IPY_MODEL_b216b7a739fc4755b580f3ae5126781f"
          }
        },
        "dfe5d11e9ad14ddf93e33b49906496aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10a208597d2e4ca8ad57b783dc73acf0",
            "placeholder": "​",
            "style": "IPY_MODEL_01642fc5555b4db5b2e170c204fa7453",
            "value": "Batches: 100%"
          }
        },
        "11c96697459447f1bb57f4320e343583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42271982fcc842d8af6cad2c2b9ce94c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ede971df705b4329ac3886d790254fd9",
            "value": 1
          }
        },
        "5059da18f88d42329967ce7055637a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b38511556d649e2bfa35121be27a771",
            "placeholder": "​",
            "style": "IPY_MODEL_b17b343b8a3e40d0808be3bd1cb43218",
            "value": " 1/1 [00:15&lt;00:00, 15.62s/it]"
          }
        },
        "b216b7a739fc4755b580f3ae5126781f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10a208597d2e4ca8ad57b783dc73acf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01642fc5555b4db5b2e170c204fa7453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42271982fcc842d8af6cad2c2b9ce94c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ede971df705b4329ac3886d790254fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b38511556d649e2bfa35121be27a771": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b17b343b8a3e40d0808be3bd1cb43218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8228f7aeff040b1b36a5ad070c2f7c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_129c2435fdeb409eb738b684ffc33068",
              "IPY_MODEL_de2e989c35ef4ba091dd56877ca85c98",
              "IPY_MODEL_12fb0729d2d74bfbb313dcb396577ef7"
            ],
            "layout": "IPY_MODEL_9311318f49a64caa93a41931576baf14"
          }
        },
        "129c2435fdeb409eb738b684ffc33068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c571e858b5ab4063aaf83063dabbb176",
            "placeholder": "​",
            "style": "IPY_MODEL_e93c6361e03440df9ff462f8882fa265",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "de2e989c35ef4ba091dd56877ca85c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1281f11112bb459a83217d14d600b589",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1beb21dd56534c54b0c637c4a95fd67e",
            "value": 2
          }
        },
        "12fb0729d2d74bfbb313dcb396577ef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_518ee95ba92a473791c05c27d7bbab6b",
            "placeholder": "​",
            "style": "IPY_MODEL_a7796b0926c6492ab43c23071062c39b",
            "value": " 2/2 [00:40&lt;00:00, 18.21s/it]"
          }
        },
        "9311318f49a64caa93a41931576baf14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c571e858b5ab4063aaf83063dabbb176": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e93c6361e03440df9ff462f8882fa265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1281f11112bb459a83217d14d600b589": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1beb21dd56534c54b0c637c4a95fd67e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "518ee95ba92a473791c05c27d7bbab6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7796b0926c6492ab43c23071062c39b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "326a4c5fe11645efa98ef3f75c17e7fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c26f4c4459b49ad8ce4f854a025dc59",
              "IPY_MODEL_5c8479ea12d6445cb7263d262a77af5a",
              "IPY_MODEL_c59d8f67ce03451f951130bdcd1a0a6a"
            ],
            "layout": "IPY_MODEL_a625714f59b44b78af5c0c5bbc67cfe2"
          }
        },
        "2c26f4c4459b49ad8ce4f854a025dc59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c2cc66d0b754831a0d9b601e466181f",
            "placeholder": "​",
            "style": "IPY_MODEL_ff0fef2bbc5d41ee8f5af9304992ba23",
            "value": "Batches: 100%"
          }
        },
        "5c8479ea12d6445cb7263d262a77af5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_539f4c4055f34c7eb903aad8da0aa1b7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27e17d82e0554156be840e79a87b38aa",
            "value": 1
          }
        },
        "c59d8f67ce03451f951130bdcd1a0a6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0abce276ce846019de78866d55b0624",
            "placeholder": "​",
            "style": "IPY_MODEL_8a271c36b9194d9185f4189c51f3b3e2",
            "value": " 1/1 [00:15&lt;00:00, 15.71s/it]"
          }
        },
        "a625714f59b44b78af5c0c5bbc67cfe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c2cc66d0b754831a0d9b601e466181f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff0fef2bbc5d41ee8f5af9304992ba23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "539f4c4055f34c7eb903aad8da0aa1b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27e17d82e0554156be840e79a87b38aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0abce276ce846019de78866d55b0624": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a271c36b9194d9185f4189c51f3b3e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54ed978665d340e78d67857952c45680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9ea34ac41d74f49996e8250e1352033",
              "IPY_MODEL_10d3cd87c4364d9a9c2c73627dccb211",
              "IPY_MODEL_ffced1e714c24d2d926cd5d2bc55d900"
            ],
            "layout": "IPY_MODEL_8c7f463517ac4293a7a14beba8e112fd"
          }
        },
        "e9ea34ac41d74f49996e8250e1352033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32e28bcef1d642e4a79e32afe2602abb",
            "placeholder": "​",
            "style": "IPY_MODEL_9ed0f1345bfb4eab937d1a919b384318",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "10d3cd87c4364d9a9c2c73627dccb211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93d31cfac02b4d4f808d90f554a39676",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98ffbbbf3d7346d6b9aa4b8d097e88e3",
            "value": 2
          }
        },
        "ffced1e714c24d2d926cd5d2bc55d900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43169a51900840938fdb64f89379a995",
            "placeholder": "​",
            "style": "IPY_MODEL_30ba3d958ac847889523432a0775cf0d",
            "value": " 2/2 [00:02&lt;00:00,  1.02it/s]"
          }
        },
        "8c7f463517ac4293a7a14beba8e112fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32e28bcef1d642e4a79e32afe2602abb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ed0f1345bfb4eab937d1a919b384318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93d31cfac02b4d4f808d90f554a39676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98ffbbbf3d7346d6b9aa4b8d097e88e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43169a51900840938fdb64f89379a995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30ba3d958ac847889523432a0775cf0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1666aefd01747d99fd93126984bd05c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_349e252d6b5246e1bd40e407d05dffe7",
              "IPY_MODEL_54c8682283f1406384b46af858e19e93",
              "IPY_MODEL_d8ff0bd46500402d9b3c0e2b992941ce"
            ],
            "layout": "IPY_MODEL_c35117e515554b6a93bedd72e05fd234"
          }
        },
        "349e252d6b5246e1bd40e407d05dffe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_948bab051f8f48709f47e2155d3e8704",
            "placeholder": "​",
            "style": "IPY_MODEL_fdc4c5c044d146a6bc7bf902dbcd400f",
            "value": "Batches: 100%"
          }
        },
        "54c8682283f1406384b46af858e19e93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07ca2c8348ec470f9fbe89f390588e52",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12e0e628936246e3b03fab9adf98afd0",
            "value": 1
          }
        },
        "d8ff0bd46500402d9b3c0e2b992941ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25dfef57085a4342b48256e8dda0607d",
            "placeholder": "​",
            "style": "IPY_MODEL_cffdccd0f2324512984f67778a1772bf",
            "value": " 1/1 [00:14&lt;00:00, 14.68s/it]"
          }
        },
        "c35117e515554b6a93bedd72e05fd234": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "948bab051f8f48709f47e2155d3e8704": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdc4c5c044d146a6bc7bf902dbcd400f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07ca2c8348ec470f9fbe89f390588e52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12e0e628936246e3b03fab9adf98afd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25dfef57085a4342b48256e8dda0607d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cffdccd0f2324512984f67778a1772bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "420f8db4207c4ff79061f60e217a5e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08cc5d688fdd48b1853046984dafee54",
              "IPY_MODEL_242cb074c86c4bfa9b6e5060b8b94c78",
              "IPY_MODEL_db5593d1401e423585bf0203f55c4b2a"
            ],
            "layout": "IPY_MODEL_2ec5ca425e534e9da82c99cf419f6c95"
          }
        },
        "08cc5d688fdd48b1853046984dafee54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a3d4de601224d238bc62739b403a642",
            "placeholder": "​",
            "style": "IPY_MODEL_715b8b93f7d54c14b1d226ed5f9b9cd5",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "242cb074c86c4bfa9b6e5060b8b94c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5feca1fccc644a297fc3a3ba67118a1",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_420ba6d451bc4f2387fbbee3724286f7",
            "value": 2
          }
        },
        "db5593d1401e423585bf0203f55c4b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e1049f4e76e43d09a06c86251a96fb2",
            "placeholder": "​",
            "style": "IPY_MODEL_56f93dda953e4653826dab2cb314edee",
            "value": " 2/2 [00:50&lt;00:00, 22.19s/it]"
          }
        },
        "2ec5ca425e534e9da82c99cf419f6c95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a3d4de601224d238bc62739b403a642": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "715b8b93f7d54c14b1d226ed5f9b9cd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5feca1fccc644a297fc3a3ba67118a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "420ba6d451bc4f2387fbbee3724286f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e1049f4e76e43d09a06c86251a96fb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56f93dda953e4653826dab2cb314edee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5f2a6c837c0490c9f96d0915b496157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81e86a14db9e4438bd9122d3e09d8915",
              "IPY_MODEL_d9fffc8f28d64a69a5e0b68c3cff99b1",
              "IPY_MODEL_cc316e535cfc4d4ea82cda03afff661f"
            ],
            "layout": "IPY_MODEL_a509041161ad4782b4422e5a6c90758e"
          }
        },
        "81e86a14db9e4438bd9122d3e09d8915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ad4ac8b5d324468b0be4c88e0687df7",
            "placeholder": "​",
            "style": "IPY_MODEL_e2620cdca97a4190be2dbd904bdce81d",
            "value": "Batches: 100%"
          }
        },
        "d9fffc8f28d64a69a5e0b68c3cff99b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e4fbb0b90454f1c9aab133712d94dad",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e871404b3cb44d8ae82d02224650bdc",
            "value": 1
          }
        },
        "cc316e535cfc4d4ea82cda03afff661f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da5e9fa296b04fd49be190bb04798fda",
            "placeholder": "​",
            "style": "IPY_MODEL_f7766a8a4fb943e4bcc1875de14c436b",
            "value": " 1/1 [00:15&lt;00:00, 15.06s/it]"
          }
        },
        "a509041161ad4782b4422e5a6c90758e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ad4ac8b5d324468b0be4c88e0687df7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2620cdca97a4190be2dbd904bdce81d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e4fbb0b90454f1c9aab133712d94dad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e871404b3cb44d8ae82d02224650bdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da5e9fa296b04fd49be190bb04798fda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7766a8a4fb943e4bcc1875de14c436b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c46d075a21f490ab2a957c54308ff54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3f0b906ffe64c0f9c0ac0b50f661276",
              "IPY_MODEL_29ca328bc13447e3ab905ea392a218ed",
              "IPY_MODEL_4c9d0145f3ea4ed9af621c67190cdb63"
            ],
            "layout": "IPY_MODEL_4622a41b86a2479f95051cec69e6e085"
          }
        },
        "a3f0b906ffe64c0f9c0ac0b50f661276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed47e5788d364d3cafcd384648d11032",
            "placeholder": "​",
            "style": "IPY_MODEL_ec6c32f226ca47d6a4a9ebbabb164bd0",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "29ca328bc13447e3ab905ea392a218ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b72973a3d3f146efa80ecb3924b36709",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4129c9ccf4f9498faa698684cf723e0f",
            "value": 2
          }
        },
        "4c9d0145f3ea4ed9af621c67190cdb63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_748fed77c19446bcac42476c8c353e1b",
            "placeholder": "​",
            "style": "IPY_MODEL_bcb78eeafcb1492cb3687ada1c5831b6",
            "value": " 2/2 [00:34&lt;00:00, 15.79s/it]"
          }
        },
        "4622a41b86a2479f95051cec69e6e085": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed47e5788d364d3cafcd384648d11032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec6c32f226ca47d6a4a9ebbabb164bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b72973a3d3f146efa80ecb3924b36709": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4129c9ccf4f9498faa698684cf723e0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "748fed77c19446bcac42476c8c353e1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcb78eeafcb1492cb3687ada1c5831b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e8a944387304515b367b254fb88f119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7872608043c44ddb387b4d00a206bb6",
              "IPY_MODEL_a62fe63ee90640c6b636aae67458d85a",
              "IPY_MODEL_884b13c5265849a5aa5801baf3c73d7f"
            ],
            "layout": "IPY_MODEL_7525ec9e065246c3a5d32a645420d9e2"
          }
        },
        "d7872608043c44ddb387b4d00a206bb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d625cecf01e0434bab149d690e6bb361",
            "placeholder": "​",
            "style": "IPY_MODEL_5fccb62caccd4618826a61b3e5eff2a8",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a62fe63ee90640c6b636aae67458d85a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddafcbd9819b454688684b3e8a0556c6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe73c0d22d164d3487f7d2ed67df9d7b",
            "value": 2
          }
        },
        "884b13c5265849a5aa5801baf3c73d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da0a314d5d264c98af7092c308af923f",
            "placeholder": "​",
            "style": "IPY_MODEL_0c0c373c8076493cb91b853e684a50e7",
            "value": " 2/2 [00:33&lt;00:00, 14.97s/it]"
          }
        },
        "7525ec9e065246c3a5d32a645420d9e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d625cecf01e0434bab149d690e6bb361": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fccb62caccd4618826a61b3e5eff2a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddafcbd9819b454688684b3e8a0556c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe73c0d22d164d3487f7d2ed67df9d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da0a314d5d264c98af7092c308af923f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c0c373c8076493cb91b853e684a50e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkAdFWVwU32H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_O_DzPCsVyWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "def get_pdf_text(pdf_path):\n",
        "    \"\"\"\n",
        "    Reads text from a PDF file.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Path to the PDF file.\n",
        "\n",
        "    Returns:\n",
        "        str: Combined text content from the PDF file.\n",
        "    \"\"\"\n",
        "    text = \"\"\n",
        "    pdf_reader = PdfReader(pdf_path)\n",
        "    for page in pdf_reader.pages:\n",
        "        if page.extract_text():  # Handle cases where text extraction may fail\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def get_text_chunks(text):\n",
        "    \"\"\"\n",
        "    Splits a large text into smaller chunks for processing.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text to split.\n",
        "\n",
        "    Returns:\n",
        "        list: List of text chunks.\n",
        "    \"\"\"\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\",\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len\n",
        "    )\n",
        "    return text_splitter.split_text(text)\n",
        "\n",
        "def get_vectorstore(text_chunks):\n",
        "    \"\"\"\n",
        "    Creates a FAISS vector store for semantic search.\n",
        "\n",
        "    Args:\n",
        "        text_chunks (list): List of text chunks.\n",
        "\n",
        "    Returns:\n",
        "        FAISS: A FAISS vector store.\n",
        "    \"\"\"\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"hkunlp/instructor-large\")\n",
        "    return FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n",
        "\n",
        "def get_conversation_chain(vectorstore):\n",
        "    \"\"\"\n",
        "    Sets up a conversational retrieval chain using the LLaMA-3.2-3B-Instruct model.\n",
        "\n",
        "    Args:\n",
        "        vectorstore (FAISS): The vector store for document retrieval.\n",
        "\n",
        "    Returns:\n",
        "        ConversationalRetrievalChain: A LangChain conversation chain.\n",
        "    \"\"\"\n",
        "    model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "\n",
        "    # Load tokenizer and model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=\"float32\"\n",
        "    )\n",
        "\n",
        "    # Create a Hugging Face pipeline\n",
        "    llm_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "    # Wrap pipeline in LangChain-compatible LLM\n",
        "    llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
        "\n",
        "    # Set up memory for conversational chain\n",
        "    memory = ConversationBufferMemory(\n",
        "        memory_key='chat_history', return_messages=True\n",
        "    )\n",
        "\n",
        "    return ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        retriever=vectorstore.as_retriever(),\n",
        "        memory=memory\n",
        "    )\n",
        "\n",
        "def main(pdf_path, question):\n",
        "    \"\"\"\n",
        "    Main function to process a PDF and answer a question.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Path to the PDF file.\n",
        "        question (str): The question to ask about the PDF content.\n",
        "    \"\"\"\n",
        "    print(\"Reading PDF...\")\n",
        "    raw_text = get_pdf_text(pdf_path)\n",
        "\n",
        "    print(\"Splitting text into chunks...\")\n",
        "    text_chunks = get_text_chunks(raw_text)\n",
        "\n",
        "    print(\"Creating vector store...\")\n",
        "    vectorstore = get_vectorstore(text_chunks)\n",
        "\n",
        "    print(\"Setting up conversation chain...\")\n",
        "    conversation_chain = get_conversation_chain(vectorstore)\n",
        "\n",
        "    print(\"Generating response...\")\n",
        "    response = conversation_chain.run(question)\n",
        "\n",
        "    # Check if response is a string or dictionary and print accordingly\n",
        "    if isinstance(response, str):\n",
        "        print(\"Response:\")\n",
        "        print(response)\n",
        "    else:\n",
        "        print(\"Response:\")\n",
        "        print(response.get('result', 'No result found'))  # In case it's a dictionary\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace 'path_to_pdf.pdf' with the actual PDF file path\n",
        "    pdf_path = \"/content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf\"\n",
        "\n",
        "    # Replace 'your_question_here' with the actual question\n",
        "    question = \"What is the book about?\"\n",
        "\n",
        "    main(pdf_path, question)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "34c5ffdaacb848d7a994a21b3459647c",
            "8e1a256622da44069b49645a8a32bf00",
            "7dddb268dc3f49b1874c04f8a1066812",
            "b61db242349a47a696ae95c25e241896",
            "f28d6db483be46b99c4ce8240193af98",
            "93595c8b81d44293aaa2813b2528dacf",
            "e4f1f02260074ac19973e29592dc8c7e",
            "2b25aae87db847eebf7d9abfd756acc6",
            "3ec5aed95898438380eb362ad8dd1b03",
            "dcddee2109dc4bd383716d1d999edbc8",
            "0cc3bf8a4a714054a1adfcc59e4c9ed8"
          ]
        },
        "id": "sbS_s4dqv7zP",
        "outputId": "5687200c-dc15-4ee9-d679-994b6cc1762d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading PDF...\n",
            "Splitting text into chunks...\n",
            "Creating vector store...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-4e55ab848418>:55: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(model_name=\"hkunlp/instructor-large\")\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up conversation chain...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34c5ffdaacb848d7a994a21b3459647c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
            "Device set to use cpu\n",
            "<ipython-input-1-4e55ab848418>:82: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
            "  llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
            "<ipython-input-1-4e55ab848418>:85: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(\n",
            "<ipython-input-1-4e55ab848418>:116: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = conversation_chain.run(question)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating response...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "My name is Percy Jackson. \n",
            "I'm twelve years old. Until a few months ago, I was a \n",
            "boarding student at Yancy Academy, a private school for \n",
            "troubled kids in upstate New York. \n",
            "Am I a troubled kid? \n",
            "Yeah. You could say that. \n",
            "[1] I could start at any point in my short miserable life \n",
            "to prove it, but things really started going bad last May, \n",
            "when our sixth-grade class took a field trip to Manhattan— \n",
            "twenty-eight mental-case kids and two teachers on a yellow \n",
            "school bus, heading to the Metropolitan Museum of Art to \n",
            "look at ancient Greek and Roman stuff. \n",
            "I know—it sounds like torture. Most Yancy field trips \n",
            "were. \n",
            "But Mr. Brunner, our Latin teacher, was leading this \n",
            "trip, so I had hopes. \n",
            "Mr. Brunner was this middle-aged guy in a motorized \n",
            "wheelchair. He had thinning hair and a scruffy beard and a \n",
            "frayed tweed jacket, which always smelled like coffee. You \n",
            "wouldn't think he'd be cool, but he told stories and jokes \n",
            "and let us play games in class. He also had this awesome\n",
            "\n",
            "2 · Three Old Ladies Knit the Socks of Death 16 \n",
            "3 · Grover Unexpectedly Loses His Pants 29 \n",
            "4 · My Mother Teaches Me Bullfighting 44 \n",
            "5 . I Play Pinochle with a Horse 57 \n",
            "6· I Become Supreme Lord of the Bathroom 75 \n",
            "7 . My Dinner Goes Up in Smoke 93 \n",
            "8 · We Capture a Flag 107 \n",
            "9 · I Am Offered a Quest 127 \n",
            "10 · I Ruin a Perfectly Good Bus 149 \n",
            "11 · We Visit the Garden Gnome Emporium 168 \n",
            "12 · We Get Advice from a Poodle 188 \n",
            "13 · I Plunge to My Death 197 \n",
            "14 · I Become a Known Fugitive 212 \n",
            "15 · A God Buys Us Cheeseburgers 219 \n",
            "16 · We Take a Zebra to Vegas 242 \n",
            "17 · We Shop for Water Beds 266 \n",
            "18 · Annabeth Does Obedience School 283 \n",
            "19 · We Find Out the Truth, Sort Of 300 \n",
            "20 · I Battle My Jerk Relative 320 \n",
            "21 · I Settle My Tab 334 \n",
            "22 · The Prophecy Comes True 354 CONTENTS Look, I didn't want to be a half-blood. \n",
            "If you're reading this because you think you might be \n",
            "one, my advice is: close this book right now. Believe what­\n",
            "\n",
            "frayed tweed jacket, which always smelled like coffee. You \n",
            "wouldn't think he'd be cool, but he told stories and jokes \n",
            "and let us play games in class. He also had this awesome \n",
            "collection of Roman armor and weapons, so he was the \n",
            "only teacher whose class didn't put me to sleep. \n",
            "I hoped the trip would be okay. At least, I hoped that \n",
            "for once I wouldn't get in trouble. \n",
            "Boy, was I wrong. \n",
            "See, bad things happen to me on field trips. Like at my \n",
            "fifth-grade school, when we went to the Saratoga battlefield, \n",
            "I had this accident with a Revolutionary War cannon. I \n",
            "wasn't aiming for the school bus, but of course I got \n",
            "expelled anyway. And before that, at my fourth-grade \n",
            "school, when we took a behind-the-scenes tour of the \n",
            "Marine World shark pool, I sort of hit the wrong lever on \n",
            "the catwalk and our class took an unplanned swim. And the \n",
            "time before that . . . Well, you get the idea. \n",
            "[2] This trip, I was determined to be good. \n",
            "All the way into the city, I put up with Nancy Bobofit,\n",
            "\n",
            "22 · The Prophecy Comes True 354 CONTENTS Look, I didn't want to be a half-blood. \n",
            "If you're reading this because you think you might be \n",
            "one, my advice is: close this book right now. Believe what­\n",
            "ever lie your mom or dad told you about your birth, and try \n",
            "to lead a normal life. \n",
            "Being a half-blood is dangerous. It's scary. Most of the \n",
            "time, it gets you killed in painful, nasty ways. \n",
            "If you're a normal kid, reading this because you think \n",
            "it's fiction, great. Read on. I envy you for being able to \n",
            "believe that none of this ever happened. \n",
            "But if you recognize yourself in these pages—if you feel \n",
            "something stirring inside—stop reading immediately. You \n",
            "might be one of us. And once you know that, it's only a mat­\n",
            "ter of time before they sense it too, and they'll come for you. \n",
            "Don't say I didn't warn you. \n",
            "My name is Percy Jackson. \n",
            "I'm twelve years old. Until a few months ago, I was a \n",
            "boarding student at Yancy Academy, a private school for \n",
            "troubled kids in upstate New York.\n",
            "\n",
            "Question: What is the book about?\n",
            "Helpful Answer: The book appears to be about Percy Jackson's experiences as a half-blood, a person with one mortal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/scorpionTaj/Chat-with-LLaMA-2-and-PDFs/issues"
      ],
      "metadata": {
        "id": "9F0pid93weBA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mWbZTohRwey_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wZpWZq9izMkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RTa6DzW0zMg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/scorpionTaj/Chat-with-LLaMA-2-and-PDFs/issues/1"
      ],
      "metadata": {
        "id": "utXWtxr_3m4t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YgHa__5IzMeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "شغال جيد"
      ],
      "metadata": {
        "id": "w9ttWtCI2bBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def get_pdf_text(pdf_path):\n",
        "    \"\"\"\n",
        "    Reads text from a PDF file.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Path to the PDF file.\n",
        "\n",
        "    Returns:\n",
        "        str: Combined text content from the PDF file.\n",
        "    \"\"\"\n",
        "    text = \"\"\n",
        "    pdf_reader = PdfReader(pdf_path)\n",
        "    for page in pdf_reader.pages:\n",
        "        if page.extract_text():  # Handle cases where text extraction may fail\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def get_text_chunks(text):\n",
        "    \"\"\"\n",
        "    Splits a large text into smaller chunks for processing.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text to split.\n",
        "\n",
        "    Returns:\n",
        "        list: List of text chunks.\n",
        "    \"\"\"\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\",\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len\n",
        "    )\n",
        "    return text_splitter.split_text(text)\n",
        "\n",
        "def get_vectorstore(text_chunks):\n",
        "    \"\"\"\n",
        "    Creates a FAISS vector store for semantic search.\n",
        "\n",
        "    Args:\n",
        "        text_chunks (list): List of text chunks.\n",
        "\n",
        "    Returns:\n",
        "        FAISS: A FAISS vector store.\n",
        "    \"\"\"\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"hkunlp/instructor-large\")\n",
        "    return FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n",
        "\n",
        "def get_conversation_chain(vectorstore):\n",
        "    \"\"\"\n",
        "    Sets up a conversational retrieval chain using the LLaMA-3.2-3B-Instruct model.\n",
        "\n",
        "    Args:\n",
        "        vectorstore (FAISS): The vector store for document retrieval.\n",
        "\n",
        "    Returns:\n",
        "        ConversationalRetrievalChain: A LangChain conversation chain.\n",
        "    \"\"\"\n",
        "    model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "\n",
        "    # Load tokenizer and model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=\"float32\"\n",
        "    )\n",
        "\n",
        "    # Create a Hugging Face pipeline\n",
        "    llm_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "    # Wrap pipeline in LangChain-compatible LLM\n",
        "    llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
        "\n",
        "    # Set up memory for conversational chain\n",
        "    memory = ConversationBufferMemory(\n",
        "        memory_key='chat_history', return_messages=True\n",
        "    )\n",
        "\n",
        "    return ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        retriever=vectorstore.as_retriever(),\n",
        "        memory=memory\n",
        "    )\n",
        "\n",
        "def chat_processor(chat_data):\n",
        "    \"\"\"\n",
        "    Processes the chat and gets a response from the conversation chain.\n",
        "\n",
        "    Args:\n",
        "        chat_data (dict): The chat data containing the question.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated response.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        question = chat_data['question']\n",
        "        # Generate response using the conversation chain\n",
        "        response = conversation_chain.run(question)\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(f\"Error in chat_processor: {str(e)}\")\n",
        "        return \"Error occurred while generating response.\"\n",
        "\n",
        "def main(pdf_path, question):\n",
        "    \"\"\"\n",
        "    Main function to process a PDF and answer a question.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Path to the PDF file.\n",
        "        question (str): The question to ask about the PDF content.\n",
        "    \"\"\"\n",
        "    print(\"Reading PDF...\")\n",
        "    raw_text = get_pdf_text(pdf_path)\n",
        "\n",
        "    print(\"Splitting text into chunks...\")\n",
        "    text_chunks = get_text_chunks(raw_text)\n",
        "\n",
        "    print(\"Creating vector store...\")\n",
        "    vectorstore = get_vectorstore(text_chunks)\n",
        "\n",
        "    print(\"Setting up conversation chain...\")\n",
        "    global conversation_chain\n",
        "    conversation_chain = get_conversation_chain(vectorstore)\n",
        "\n",
        "    print(\"Generating response...\")\n",
        "    # Run the chat processing in parallel\n",
        "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
        "        responses = list(executor.map(chat_processor, [{'question': question}]))\n",
        "\n",
        "    # Only print the last response\n",
        "    print(\"Response:\")\n",
        "    print(responses[-1])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace 'path_to_pdf.pdf' with the actual PDF file path\n",
        "    pdf_path = \"/content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf\"\n",
        "\n",
        "    # Replace 'your_question_here' with the actual question\n",
        "    question = \"What is the name of the hero in the book?\"\n",
        "\n",
        "    main(pdf_path, question)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "442d1a063f15462bacee2401e076d0bd",
            "cd7fd57c86094a1399fda00cfa04b6dd",
            "93596463179e4a75bb127e4da2efd47c",
            "7eddf9a942314028a847cc998a426919",
            "d92ec5bed21346abace37c39dd68fc35",
            "07635f3d2663480d84e85fee49bc6c53",
            "a1d98b09914a4a3290e06c68008e2400",
            "296bfd5fd1164d6b9b3bd8c0f894c0c6",
            "5a999d420679411b903fde6b86d366e8",
            "34eae9077b944a478576bf1ec8795a88",
            "c1e11fab36404d078e6f04c6652ff163"
          ]
        },
        "id": "0CY-PuzOzMbR",
        "outputId": "0364fb1a-ed0e-4f65-cf36-f93da9747f71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading PDF...\n",
            "Splitting text into chunks...\n",
            "Creating vector store...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-85e28a07210d>:56: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(model_name=\"hkunlp/instructor-large\")\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up conversation chain...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "442d1a063f15462bacee2401e076d0bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu and disk.\n",
            "Device set to use cpu\n",
            "<ipython-input-1-85e28a07210d>:83: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
            "  llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
            "<ipython-input-1-85e28a07210d>:86: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(\n",
            "<ipython-input-1-85e28a07210d>:109: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = conversation_chain.run(question)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating response...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "RICK RIORDAN \n",
            "MIRAMAX BOOKS \n",
            "HYPERION BOOKS FOR CHILDREN \n",
            "NEW YORK Copyright © 2005 by Rick Riordan \n",
            "All rights reserved. No part of this book may be reproduced or transmitted in any \n",
            "form or by any means, electronic or mechanical, including photocopying, recording, \n",
            "or by any information storage and retrieval system, without written permission from \n",
            "the publisher. For information address Hyperion Books for Children, \n",
            "114 Fifth Avenue, New York, New York 10011-5690. \n",
            "First Edition \n",
            "5 7 9 10 8 6 \n",
            "Printed in the United States of America \n",
            "Library of Congress Cataloging-in-Publication Data on file. \n",
            "ISBN 0-7868-5629-7 (hardcover) \n",
            "Reinforced binding \n",
            "Visit www.hyperionbooksforchildren.com To Haley, \n",
            "who heard the story first 1 · I Accidentally Vaporize My Pre-algebra Teacher 1 \n",
            "2 · Three Old Ladies Knit the Socks of Death 16 \n",
            "3 · Grover Unexpectedly Loses His Pants 29 \n",
            "4 · My Mother Teaches Me Bullfighting 44 \n",
            "5 . I Play Pinochle with a Horse 57\n",
            "\n",
            "My name is Percy Jackson. \n",
            "I'm twelve years old. Until a few months ago, I was a \n",
            "boarding student at Yancy Academy, a private school for \n",
            "troubled kids in upstate New York. \n",
            "Am I a troubled kid? \n",
            "Yeah. You could say that. \n",
            "[1] I could start at any point in my short miserable life \n",
            "to prove it, but things really started going bad last May, \n",
            "when our sixth-grade class took a field trip to Manhattan— \n",
            "twenty-eight mental-case kids and two teachers on a yellow \n",
            "school bus, heading to the Metropolitan Museum of Art to \n",
            "look at ancient Greek and Roman stuff. \n",
            "I know—it sounds like torture. Most Yancy field trips \n",
            "were. \n",
            "But Mr. Brunner, our Latin teacher, was leading this \n",
            "trip, so I had hopes. \n",
            "Mr. Brunner was this middle-aged guy in a motorized \n",
            "wheelchair. He had thinning hair and a scruffy beard and a \n",
            "frayed tweed jacket, which always smelled like coffee. You \n",
            "wouldn't think he'd be cool, but he told stories and jokes \n",
            "and let us play games in class. He also had this awesome\n",
            "\n",
            "frayed tweed jacket, which always smelled like coffee. You \n",
            "wouldn't think he'd be cool, but he told stories and jokes \n",
            "and let us play games in class. He also had this awesome \n",
            "collection of Roman armor and weapons, so he was the \n",
            "only teacher whose class didn't put me to sleep. \n",
            "I hoped the trip would be okay. At least, I hoped that \n",
            "for once I wouldn't get in trouble. \n",
            "Boy, was I wrong. \n",
            "See, bad things happen to me on field trips. Like at my \n",
            "fifth-grade school, when we went to the Saratoga battlefield, \n",
            "I had this accident with a Revolutionary War cannon. I \n",
            "wasn't aiming for the school bus, but of course I got \n",
            "expelled anyway. And before that, at my fourth-grade \n",
            "school, when we took a behind-the-scenes tour of the \n",
            "Marine World shark pool, I sort of hit the wrong lever on \n",
            "the catwalk and our class took an unplanned swim. And the \n",
            "time before that . . . Well, you get the idea. \n",
            "[2] This trip, I was determined to be good. \n",
            "All the way into the city, I put up with Nancy Bobofit,\n",
            "\n",
            "22 · The Prophecy Comes True 354 CONTENTS Look, I didn't want to be a half-blood. \n",
            "If you're reading this because you think you might be \n",
            "one, my advice is: close this book right now. Believe what­\n",
            "ever lie your mom or dad told you about your birth, and try \n",
            "to lead a normal life. \n",
            "Being a half-blood is dangerous. It's scary. Most of the \n",
            "time, it gets you killed in painful, nasty ways. \n",
            "If you're a normal kid, reading this because you think \n",
            "it's fiction, great. Read on. I envy you for being able to \n",
            "believe that none of this ever happened. \n",
            "But if you recognize yourself in these pages—if you feel \n",
            "something stirring inside—stop reading immediately. You \n",
            "might be one of us. And once you know that, it's only a mat­\n",
            "ter of time before they sense it too, and they'll come for you. \n",
            "Don't say I didn't warn you. \n",
            "My name is Percy Jackson. \n",
            "I'm twelve years old. Until a few months ago, I was a \n",
            "boarding student at Yancy Academy, a private school for \n",
            "troubled kids in upstate New York.\n",
            "\n",
            "Question: What is the name of the hero in the book?\n",
            "Helpful Answer: The hero's name is Percy Jackson.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "efaxTeiF4Jnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h4nedbiE4JlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KgXskhCp4Jit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PzBgv73K4JfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "شغال"
      ],
      "metadata": {
        "id": "6Nf-EpOM7x5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def get_pdf_text(pdf_path):\n",
        "    \"\"\"\n",
        "    Reads text from a PDF file.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Path to the PDF file.\n",
        "\n",
        "    Returns:\n",
        "        str: Combined text content from the PDF file.\n",
        "    \"\"\"\n",
        "    text = \"\"\n",
        "    pdf_reader = PdfReader(pdf_path)\n",
        "    for page in pdf_reader.pages:\n",
        "        if page.extract_text():  # Handle cases where text extraction may fail\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def get_text_chunks(text):\n",
        "    \"\"\"\n",
        "    Splits a large text into smaller chunks for processing.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text to split.\n",
        "\n",
        "    Returns:\n",
        "        list: List of text chunks.\n",
        "    \"\"\"\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\",\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len\n",
        "    )\n",
        "    return text_splitter.split_text(text)\n",
        "\n",
        "def get_vectorstore(text_chunks):\n",
        "    \"\"\"\n",
        "    Creates a FAISS vector store for semantic search.\n",
        "\n",
        "    Args:\n",
        "        text_chunks (list): List of text chunks.\n",
        "\n",
        "    Returns:\n",
        "        FAISS: A FAISS vector store.\n",
        "    \"\"\"\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"hkunlp/instructor-large\")\n",
        "    return FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n",
        "\n",
        "def get_conversation_chain(vectorstore):\n",
        "    \"\"\"\n",
        "    Sets up a conversational retrieval chain using the LLaMA-3.2-3B-Instruct model.\n",
        "\n",
        "    Args:\n",
        "        vectorstore (FAISS): The vector store for document retrieval.\n",
        "\n",
        "    Returns:\n",
        "        ConversationalRetrievalChain: A LangChain conversation chain.\n",
        "    \"\"\"\n",
        "    model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "\n",
        "    # Load tokenizer and model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=\"float32\"\n",
        "    )\n",
        "\n",
        "    # Create a Hugging Face pipeline\n",
        "    llm_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "    # Wrap pipeline in LangChain-compatible LLM\n",
        "    llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
        "\n",
        "    # Set up memory for conversational chain\n",
        "    memory = ConversationBufferMemory(\n",
        "        memory_key='chat_history', return_messages=True\n",
        "    )\n",
        "\n",
        "    return ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        retriever=vectorstore.as_retriever(),\n",
        "        memory=memory\n",
        "    )\n",
        "\n",
        "def chat_processor(chat_data):\n",
        "    \"\"\"\n",
        "    Processes the chat and gets a response from the conversation chain.\n",
        "\n",
        "    Args:\n",
        "        chat_data (dict): The chat data containing the question.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated response.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        question = chat_data['question']\n",
        "        # Generate response using the conversation chain\n",
        "        response = conversation_chain.run(question)\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(f\"Error in chat_processor: {str(e)}\")\n",
        "        return \"Error occurred while generating response.\"\n",
        "\n",
        "def main(pdf_path, question):\n",
        "    \"\"\"\n",
        "    Main function to process a PDF and answer a question.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Path to the PDF file.\n",
        "        question (str): The question to ask about the PDF content.\n",
        "    \"\"\"\n",
        "    print(\"Reading PDF...\")  # This can be kept to show process, but content is not printed.\n",
        "    raw_text = get_pdf_text(pdf_path)\n",
        "\n",
        "    print(\"Splitting text into chunks...\")  # The splitting process is kept, no text is shown.\n",
        "    text_chunks = get_text_chunks(raw_text)\n",
        "\n",
        "    print(\"Creating vector store...\")  # Creating the vector store, no text is displayed.\n",
        "    vectorstore = get_vectorstore(text_chunks)\n",
        "\n",
        "    print(\"Setting up conversation chain...\")  # Setting up the chain without showing intermediate content.\n",
        "    global conversation_chain\n",
        "    conversation_chain = get_conversation_chain(vectorstore)\n",
        "\n",
        "    print(\"Generating response...\")  # This is kept to show process, but no intermediate text is printed.\n",
        "    # Run the chat processing in parallel\n",
        "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
        "        responses = list(executor.map(chat_processor, [{'question': question}]))\n",
        "\n",
        "    # Only print the last response\n",
        "    print(\"Response:\")\n",
        "    print(responses[-1])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace 'path_to_pdf.pdf' with the actual PDF file path\n",
        "    pdf_path = \"/content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf\"\n",
        "\n",
        "    # Replace 'your_question_here' with the actual question\n",
        "    question = \"Who is Percy in the book and what does he do?\"\n",
        "\n",
        "    main(pdf_path, question)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "86a7b57356454530933052ae5f44253d",
            "157ca5df468f49d7b1b130161d43960d",
            "2986ebe2dc7e43aa9d081ed164c480b9",
            "7e8bdecf1d0b41ad882f2c27c74933fd",
            "174e7b02ee9f4d349c3b0bc12e9134f1",
            "877e548f3f5c4b8688a8acba05852002",
            "76fb21af620e45bc8f5b5a9ee117618e",
            "5dd1a34b38e947d08f20ba12d2813176",
            "8a4203f2239b410181759350c086cd98",
            "c282887d7a094dcba80b7610c6eede3e",
            "aa80a7c82e56471692255847c27150f2"
          ]
        },
        "id": "Yqjv7gzf4JcM",
        "outputId": "507d15c2-4b90-4173-fb10-9bf389990972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading PDF...\n",
            "Splitting text into chunks...\n",
            "Creating vector store...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-bd986103be0d>:56: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(model_name=\"hkunlp/instructor-large\")\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up conversation chain...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86a7b57356454530933052ae5f44253d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu and disk.\n",
            "Device set to use cpu\n",
            "<ipython-input-1-bd986103be0d>:83: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
            "  llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
            "<ipython-input-1-bd986103be0d>:86: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(\n",
            "<ipython-input-1-bd986103be0d>:109: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = conversation_chain.run(question)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating response...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "My name is Percy Jackson. \n",
            "I'm twelve years old. Until a few months ago, I was a \n",
            "boarding student at Yancy Academy, a private school for \n",
            "troubled kids in upstate New York. \n",
            "Am I a troubled kid? \n",
            "Yeah. You could say that. \n",
            "[1] I could start at any point in my short miserable life \n",
            "to prove it, but things really started going bad last May, \n",
            "when our sixth-grade class took a field trip to Manhattan— \n",
            "twenty-eight mental-case kids and two teachers on a yellow \n",
            "school bus, heading to the Metropolitan Museum of Art to \n",
            "look at ancient Greek and Roman stuff. \n",
            "I know—it sounds like torture. Most Yancy field trips \n",
            "were. \n",
            "But Mr. Brunner, our Latin teacher, was leading this \n",
            "trip, so I had hopes. \n",
            "Mr. Brunner was this middle-aged guy in a motorized \n",
            "wheelchair. He had thinning hair and a scruffy beard and a \n",
            "frayed tweed jacket, which always smelled like coffee. You \n",
            "wouldn't think he'd be cool, but he told stories and jokes \n",
            "and let us play games in class. He also had this awesome\n",
            "\n",
            "22 · The Prophecy Comes True 354 CONTENTS Look, I didn't want to be a half-blood. \n",
            "If you're reading this because you think you might be \n",
            "one, my advice is: close this book right now. Believe what­\n",
            "ever lie your mom or dad told you about your birth, and try \n",
            "to lead a normal life. \n",
            "Being a half-blood is dangerous. It's scary. Most of the \n",
            "time, it gets you killed in painful, nasty ways. \n",
            "If you're a normal kid, reading this because you think \n",
            "it's fiction, great. Read on. I envy you for being able to \n",
            "believe that none of this ever happened. \n",
            "But if you recognize yourself in these pages—if you feel \n",
            "something stirring inside—stop reading immediately. You \n",
            "might be one of us. And once you know that, it's only a mat­\n",
            "ter of time before they sense it too, and they'll come for you. \n",
            "Don't say I didn't warn you. \n",
            "My name is Percy Jackson. \n",
            "I'm twelve years old. Until a few months ago, I was a \n",
            "boarding student at Yancy Academy, a private school for \n",
            "troubled kids in upstate New York.\n",
            "\n",
            "RICK RIORDAN \n",
            "MIRAMAX BOOKS \n",
            "HYPERION BOOKS FOR CHILDREN \n",
            "NEW YORK Copyright © 2005 by Rick Riordan \n",
            "All rights reserved. No part of this book may be reproduced or transmitted in any \n",
            "form or by any means, electronic or mechanical, including photocopying, recording, \n",
            "or by any information storage and retrieval system, without written permission from \n",
            "the publisher. For information address Hyperion Books for Children, \n",
            "114 Fifth Avenue, New York, New York 10011-5690. \n",
            "First Edition \n",
            "5 7 9 10 8 6 \n",
            "Printed in the United States of America \n",
            "Library of Congress Cataloging-in-Publication Data on file. \n",
            "ISBN 0-7868-5629-7 (hardcover) \n",
            "Reinforced binding \n",
            "Visit www.hyperionbooksforchildren.com To Haley, \n",
            "who heard the story first 1 · I Accidentally Vaporize My Pre-algebra Teacher 1 \n",
            "2 · Three Old Ladies Knit the Socks of Death 16 \n",
            "3 · Grover Unexpectedly Loses His Pants 29 \n",
            "4 · My Mother Teaches Me Bullfighting 44 \n",
            "5 . I Play Pinochle with a Horse 57\n",
            "\n",
            "But his wife hid baby Zeus, and gave Kronos a rock to eat \n",
            "instead. And later, when Zeus grew up, he tricked his dad, \n",
            "Kronos, into barfing up his brothers and sisters—\" \n",
            "\"Eeew!\" said one of the girls behind me. \n",
            "\"—and so there was this big fight between the gods and \n",
            "the Titans,\" I continued, \"and the gods won.\" \n",
            "[5] Some snickers from the group. \n",
            "Behind me, Nancy Bobofit mumbled to a friend, \"Like \n",
            "we're going to use this in real life. Like it's going to say on \n",
            "our job applications, 'Please explain why Kronos ate his \n",
            "kids.' \" \n",
            "\"And why, Mr. Jackson,\" Brunner said, \"to paraphrase \n",
            "Miss Bobofit's excellent question, does this matter in real \n",
            "life?\" \n",
            "\"Busted,\" Grover muttered. \n",
            "\"Shut up,\" Nancy hissed, her face even brighter red than \n",
            "her hair. \n",
            "At least Nancy got packed, too. Mr. Brunner was the \n",
            "only one who ever caught her saying anything wrong. He \n",
            "had radar ears. \n",
            "I thought about his question, and shrugged. \"I don't \n",
            "know, sir.\"\n",
            "\n",
            "Question: Who is Percy in the book and what does he do?\n",
            "Helpful Answer: I don't know. \n",
            "I don't know the answer to this question based on the provided text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "شغال"
      ],
      "metadata": {
        "id": "v9x3l4ua9hEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def get_pdf_text(pdf_path):\n",
        "    \"\"\"\n",
        "    Reads text from a PDF file.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Path to the PDF file.\n",
        "\n",
        "    Returns:\n",
        "        str: Combined text content from the PDF file.\n",
        "    \"\"\"\n",
        "    text = \"\"\n",
        "    pdf_reader = PdfReader(pdf_path)\n",
        "    for page in pdf_reader.pages:\n",
        "        if page.extract_text():  # Handle cases where text extraction may fail\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def get_text_chunks(text):\n",
        "    \"\"\"\n",
        "    Splits a large text into smaller chunks for processing.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text to split.\n",
        "\n",
        "    Returns:\n",
        "        list: List of text chunks.\n",
        "    \"\"\"\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\",\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len\n",
        "    )\n",
        "    return text_splitter.split_text(text)\n",
        "\n",
        "def get_vectorstore(text_chunks):\n",
        "    \"\"\"\n",
        "    Creates a FAISS vector store for semantic search.\n",
        "\n",
        "    Args:\n",
        "        text_chunks (list): List of text chunks.\n",
        "\n",
        "    Returns:\n",
        "        FAISS: A FAISS vector store.\n",
        "    \"\"\"\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"hkunlp/instructor-large\")\n",
        "    return FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n",
        "\n",
        "def get_conversation_chain(vectorstore):\n",
        "    \"\"\"\n",
        "    Sets up a conversational retrieval chain using the LLaMA-3.2-3B-Instruct model.\n",
        "\n",
        "    Args:\n",
        "        vectorstore (FAISS): The vector store for document retrieval.\n",
        "\n",
        "    Returns:\n",
        "        ConversationalRetrievalChain: A LangChain conversation chain.\n",
        "    \"\"\"\n",
        "    model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "\n",
        "    # Load tokenizer and model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=\"float32\"\n",
        "    )\n",
        "\n",
        "    # Create a Hugging Face pipeline\n",
        "    llm_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "    # Wrap pipeline in LangChain-compatible LLM\n",
        "    llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
        "\n",
        "    # Set up memory for conversational chain\n",
        "    memory = ConversationBufferMemory(\n",
        "        memory_key='chat_history', return_messages=True\n",
        "    )\n",
        "\n",
        "    return ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        retriever=vectorstore.as_retriever(),\n",
        "        memory=memory\n",
        "    )\n",
        "\n",
        "def chat_processor(chat_data):\n",
        "    \"\"\"\n",
        "    Processes the chat and gets a response from the conversation chain.\n",
        "\n",
        "    Args:\n",
        "        chat_data (dict): The chat data containing the question.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated response.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        question = chat_data['question']\n",
        "        # Generate response using the conversation chain\n",
        "        response = conversation_chain.run(question)\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(f\"Error in chat_processor: {str(e)}\")\n",
        "        return \"Error occurred while generating response.\"\n",
        "\n",
        "def main(pdf_path, question):\n",
        "    \"\"\"\n",
        "    Main function to process a PDF and answer a question.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Path to the PDF file.\n",
        "        question (str): The question to ask about the PDF content.\n",
        "    \"\"\"\n",
        "    print(\"Reading PDF...\")  # This can be kept to show process, but content is not printed.\n",
        "    raw_text = get_pdf_text(pdf_path)\n",
        "\n",
        "    print(\"Splitting text into chunks...\")  # The splitting process is kept, no text is shown.\n",
        "    text_chunks = get_text_chunks(raw_text)\n",
        "\n",
        "    print(\"Creating vector store...\")  # Creating the vector store, no text is displayed.\n",
        "    vectorstore = get_vectorstore(text_chunks)\n",
        "\n",
        "    print(\"Setting up conversation chain...\")  # Setting up the chain without showing intermediate content.\n",
        "    global conversation_chain\n",
        "    conversation_chain = get_conversation_chain(vectorstore)\n",
        "\n",
        "    print(\"Generating response...\")  # This is kept to show process, but no intermediate text is printed.\n",
        "    # Run the chat processing in parallel\n",
        "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
        "        responses = list(executor.map(chat_processor, [{'question': question}]))\n",
        "\n",
        "    # Only print the last response\n",
        "    print(\"Response:\")\n",
        "    print(responses[-1])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace 'path_to_pdf.pdf' with the actual PDF file path\n",
        "    pdf_path = \"/content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf\"\n",
        "\n",
        "    # Replace 'your_question_here' with the actual question\n",
        "    question = \"How did Percy's story begin?\"\n",
        "\n",
        "    main(pdf_path, question)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8145391460f342b8a64be170a4f8b989",
            "4005004dff0643c694056e1de3818fca",
            "5d900adf6d4949a0b4351d5c3ab7d368",
            "adcb80c474bd4ee6b3f833dec4971e1f",
            "ca4a16b9da524696b209668a7178dde4",
            "8c24651e8af64fee9168eaff5d91efb1",
            "f396b5f738284e5db9fb45d6af8df42c",
            "690846bd52354029a5ed6e80f3b087a9",
            "863eae13f6684cd5aaf01bec78ed392f",
            "93bcccaeddd14c388831835008df1816",
            "d29092da064c4cfb8d1ff2a68a52d235"
          ]
        },
        "id": "qzB34qB36tGs",
        "outputId": "2a2900f5-d88e-4b18-e2f8-1a459281b6c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading PDF...\n",
            "Splitting text into chunks...\n",
            "Creating vector store...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-e930b3513ead>:56: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(model_name=\"hkunlp/instructor-large\")\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up conversation chain...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8145391460f342b8a64be170a4f8b989"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu and disk.\n",
            "Device set to use cpu\n",
            "<ipython-input-1-e930b3513ead>:83: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
            "  llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
            "<ipython-input-1-e930b3513ead>:86: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(\n",
            "<ipython-input-1-e930b3513ead>:109: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = conversation_chain.run(question)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating response...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "My name is Percy Jackson. \n",
            "I'm twelve years old. Until a few months ago, I was a \n",
            "boarding student at Yancy Academy, a private school for \n",
            "troubled kids in upstate New York. \n",
            "Am I a troubled kid? \n",
            "Yeah. You could say that. \n",
            "[1] I could start at any point in my short miserable life \n",
            "to prove it, but things really started going bad last May, \n",
            "when our sixth-grade class took a field trip to Manhattan— \n",
            "twenty-eight mental-case kids and two teachers on a yellow \n",
            "school bus, heading to the Metropolitan Museum of Art to \n",
            "look at ancient Greek and Roman stuff. \n",
            "I know—it sounds like torture. Most Yancy field trips \n",
            "were. \n",
            "But Mr. Brunner, our Latin teacher, was leading this \n",
            "trip, so I had hopes. \n",
            "Mr. Brunner was this middle-aged guy in a motorized \n",
            "wheelchair. He had thinning hair and a scruffy beard and a \n",
            "frayed tweed jacket, which always smelled like coffee. You \n",
            "wouldn't think he'd be cool, but he told stories and jokes \n",
            "and let us play games in class. He also had this awesome\n",
            "\n",
            "22 · The Prophecy Comes True 354 CONTENTS Look, I didn't want to be a half-blood. \n",
            "If you're reading this because you think you might be \n",
            "one, my advice is: close this book right now. Believe what­\n",
            "ever lie your mom or dad told you about your birth, and try \n",
            "to lead a normal life. \n",
            "Being a half-blood is dangerous. It's scary. Most of the \n",
            "time, it gets you killed in painful, nasty ways. \n",
            "If you're a normal kid, reading this because you think \n",
            "it's fiction, great. Read on. I envy you for being able to \n",
            "believe that none of this ever happened. \n",
            "But if you recognize yourself in these pages—if you feel \n",
            "something stirring inside—stop reading immediately. You \n",
            "might be one of us. And once you know that, it's only a mat­\n",
            "ter of time before they sense it too, and they'll come for you. \n",
            "Don't say I didn't warn you. \n",
            "My name is Percy Jackson. \n",
            "I'm twelve years old. Until a few months ago, I was a \n",
            "boarding student at Yancy Academy, a private school for \n",
            "troubled kids in upstate New York.\n",
            "\n",
            "But his wife hid baby Zeus, and gave Kronos a rock to eat \n",
            "instead. And later, when Zeus grew up, he tricked his dad, \n",
            "Kronos, into barfing up his brothers and sisters—\" \n",
            "\"Eeew!\" said one of the girls behind me. \n",
            "\"—and so there was this big fight between the gods and \n",
            "the Titans,\" I continued, \"and the gods won.\" \n",
            "[5] Some snickers from the group. \n",
            "Behind me, Nancy Bobofit mumbled to a friend, \"Like \n",
            "we're going to use this in real life. Like it's going to say on \n",
            "our job applications, 'Please explain why Kronos ate his \n",
            "kids.' \" \n",
            "\"And why, Mr. Jackson,\" Brunner said, \"to paraphrase \n",
            "Miss Bobofit's excellent question, does this matter in real \n",
            "life?\" \n",
            "\"Busted,\" Grover muttered. \n",
            "\"Shut up,\" Nancy hissed, her face even brighter red than \n",
            "her hair. \n",
            "At least Nancy got packed, too. Mr. Brunner was the \n",
            "only one who ever caught her saying anything wrong. He \n",
            "had radar ears. \n",
            "I thought about his question, and shrugged. \"I don't \n",
            "know, sir.\"\n",
            "\n",
            "RICK RIORDAN \n",
            "MIRAMAX BOOKS \n",
            "HYPERION BOOKS FOR CHILDREN \n",
            "NEW YORK Copyright © 2005 by Rick Riordan \n",
            "All rights reserved. No part of this book may be reproduced or transmitted in any \n",
            "form or by any means, electronic or mechanical, including photocopying, recording, \n",
            "or by any information storage and retrieval system, without written permission from \n",
            "the publisher. For information address Hyperion Books for Children, \n",
            "114 Fifth Avenue, New York, New York 10011-5690. \n",
            "First Edition \n",
            "5 7 9 10 8 6 \n",
            "Printed in the United States of America \n",
            "Library of Congress Cataloging-in-Publication Data on file. \n",
            "ISBN 0-7868-5629-7 (hardcover) \n",
            "Reinforced binding \n",
            "Visit www.hyperionbooksforchildren.com To Haley, \n",
            "who heard the story first 1 · I Accidentally Vaporize My Pre-algebra Teacher 1 \n",
            "2 · Three Old Ladies Knit the Socks of Death 16 \n",
            "3 · Grover Unexpectedly Loses His Pants 29 \n",
            "4 · My Mother Teaches Me Bullfighting 44 \n",
            "5 . I Play Pinochle with a Horse 57\n",
            "\n",
            "Question: How did Percy's story begin?\n",
            "Helpful Answer: According to the text, Percy's story begins with a field trip to Manhattan, where his class visited\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq()\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"llama3-8b-8192\",\n",
        "    messages=[],\n",
        "    temperature=1,\n",
        "    max_tokens=1024,\n",
        "    top_p=1,\n",
        "    stream=True,\n",
        "    stop=None,\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "80OplQJ45S0L",
        "outputId": "ec0d5258-2e1e-4dfc-982d-0819ea528d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'groq'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d59100312ae9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgroq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGroq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGroq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m completion = client.chat.completions.create(\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"llama3-8b-8192\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'groq'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OZ79I3CY7-VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YaZqV0fY7-Sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KBhqCBAf7-Ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F2PEOGWv7-LT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HIQ2ELzi7-It"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ها أنا قد كتبت لك برنامج بسيط بلغة بايثون لإنشاء شات مع الكتب والكود، يستخدم نماذج hkunlp/instructor-large و meta-llama/Llama-3.2-3B-Instruct، و يتم تشغيله على المعالج فقط بدون GPU. يمكنك تشغيله في كولاب جوجل.\n",
        "\n",
        "```python\n",
        "# استيراد المكتبات الضرورية\n",
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "# تحميل النماذج\n",
        "model1 = AutoModelForSeq2SeqLM.from_pretrained(\"hkunlp/instructor-large\")\n",
        "tokenizer1 = AutoTokenizer.from_pretrained(\"hkunlp/instructor-large\")\n",
        "\n",
        "model2 = AutoModelForSeq2SeqLM.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
        "tokenizer2 = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
        "\n",
        "# ضبط Device على المعالج فقط\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "# نقل النماذج إلى المعالج\n",
        "model1.to(device)\n",
        "model2.to(device)\n",
        "\n",
        "def chat_with_book(question, model, tokenizer):\n",
        "    # معالجة السؤال\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        question,\n",
        "        add_special_tokens=True,\n",
        "        max_length=512,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    # تمرير السؤال من خلال النموذج\n",
        "    outputs = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "    # معالجة الإجابة\n",
        "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return answer\n",
        "\n",
        "# تقديم سؤال\n",
        "question = input(\"ادخل سؤالك: \")\n",
        "\n",
        "# الحصول على إجابة من النموذج الأول\n",
        "answer1 = chat_with_book(question, model1, tokenizer1)\n",
        "\n",
        "# الحصول على إجابة من النموذج الثاني\n",
        "answer2 = chat_with_book(question, model2, tokenizer2)\n",
        "\n",
        "# طباعة الإجابات\n",
        "print(\"الإجابة من النموذج الأول: \", answer1)\n",
        "print(\"الإجابة من النموذج الثاني: \", answer2)\n",
        "```"
      ],
      "metadata": {
        "id": "kjEPGd8X7-FD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تثبيت المكتبات اللازمة\n",
        "#!pip install transformers sentence-transformers accelerate torch PyPDF2\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pathlib import Path\n",
        "import os\n",
        "import PyPDF2\n",
        "\n",
        "# التحقق من توفر المعالج (CPU)\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"سيتم استخدام المعالج (CPU) نظرًا لعدم توفر معالج الرسوميات (GPU).\")\n",
        "else:\n",
        "    print(\"تم الكشف عن معالج الرسوميات (GPU)، ولكن سيتم استخدام المعالج (CPU) حسب طلبك.\")\n",
        "\n",
        "# تحديد مسار الكتاب (يمكنك تغييره)\n",
        "book_path = 'book.pdf'  # استبدل هذا بالمسار الفعلي للكتاب PDF الخاص بك\n",
        "\n",
        "# 1. معالجة الكتاب: استخراج النص وتقسيمه إلى فقرات (تعديل لملفات PDF)\n",
        "def load_and_split_book(file_path):\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"لم يتم العثور على الملف {file_path}\")\n",
        "        return []\n",
        "    try:\n",
        "        with open(file_path, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page_num in range(len(pdf_reader.pages)):\n",
        "                page = pdf_reader.pages[page_num]\n",
        "                text += page.extract_text()\n",
        "            paragraphs = text.split('\\n\\n')  # تقسيم النص إلى فقرات بناءً على فاصل سطرين فارغين\n",
        "            return paragraphs\n",
        "    except Exception as e:\n",
        "         print(f\"حدث خطأ أثناء معالجة ملف PDF: {e}\")\n",
        "         return []\n",
        "\n",
        "# 2. تحميل النموذج instructor-large للتمثيل النصي\n",
        "print(\"جاري تحميل نموذج instructor-large...\")\n",
        "instructor_model = SentenceTransformer('hkunlp/instructor-large', device='cpu')\n",
        "print(\"تم تحميل نموذج instructor-large.\")\n",
        "\n",
        "# 3. إنشاء تمثيلات نصية (embeddings) للفقرات\n",
        "def generate_embeddings(paragraphs, model):\n",
        "    embeddings = model.encode(paragraphs, show_progress_bar=True)\n",
        "    return embeddings\n",
        "\n",
        "# 4. تحميل نموذج Llama-3.2-3B-Instruct للدردشة\n",
        "print(\"جاري تحميل نموذج Llama-3.2-3B-Instruct...\")\n",
        "llama_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3-8B-Instruct\")\n",
        "llama_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3-8B-Instruct\", device_map=\"cpu\",low_cpu_mem_usage=True)\n",
        "print(\"تم تحميل نموذج Llama-3.2-3B-Instruct.\")\n",
        "\n",
        "# 5. وظيفة البحث عن الفقرات الأكثر صلة بالسؤال\n",
        "def search_relevant_paragraphs(query, embeddings, paragraphs, model, top_k=5):\n",
        "    query_embedding = model.encode(query)\n",
        "    similarities = torch.nn.functional.cosine_similarity(torch.tensor(query_embedding).unsqueeze(0), torch.tensor(embeddings))\n",
        "    top_indices = torch.topk(similarities, k=top_k).indices\n",
        "    return [paragraphs[i] for i in top_indices]\n",
        "\n",
        "# 6. وظيفة إنشاء الإجابة باستخدام Llama-3.2-3B-Instruct\n",
        "def generate_answer(query, context, tokenizer, model):\n",
        "    prompt = f\"Based on the following context, answer the question: Context: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(**inputs, max_length=200,do_sample=True, top_k=50, top_p=0.95)\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# 7. الواجهة الرئيسية للدردشة\n",
        "def chat_with_book(book_path):\n",
        "    paragraphs = load_and_split_book(book_path)\n",
        "\n",
        "    if not paragraphs:\n",
        "        print(\"لا يمكن بدء الدردشة، الرجاء التأكد من وجود الكتاب.\")\n",
        "        return\n",
        "\n",
        "    embeddings = generate_embeddings(paragraphs, instructor_model)\n",
        "\n",
        "    while True:\n",
        "        query = input(\"اطرح سؤالك (أو اكتب 'خروج' للخروج): \")\n",
        "        if query.lower() == 'خروج':\n",
        "            break\n",
        "\n",
        "        relevant_paragraphs = search_relevant_paragraphs(query, embeddings, paragraphs, instructor_model)\n",
        "        context = \" \".join(relevant_paragraphs)\n",
        "\n",
        "        answer = generate_answer(query, context, llama_tokenizer, llama_model)\n",
        "        print(\"الإجابة:\", answer)\n",
        "\n",
        "# بدء الدردشة\n",
        "if __name__ == \"__main__\":\n",
        "  chat_with_book(book_path)"
      ],
      "metadata": {
        "id": "ASHzL0F083AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تثبيت المكتبات اللازمة\n",
        "#!pip install transformers sentence-transformers accelerate torch PyPDF2\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pathlib import Path\n",
        "import os\n",
        "import PyPDF2\n",
        "\n",
        "# التحقق من توفر المعالج (CPU)\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"سيتم استخدام المعالج (CPU) نظرًا لعدم توفر معالج الرسوميات (GPU).\")\n",
        "else:\n",
        "    print(\"تم الكشف عن معالج الرسوميات (GPU)، ولكن سيتم استخدام المعالج (CPU) حسب طلبك.\")\n",
        "\n",
        "# تحديد مسار الكتاب (يمكنك تغييره)\n",
        "book_path = '/content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf'  # استبدل هذا بالمسار الفعلي للكتاب PDF الخاص بك\n",
        "\n",
        "# 1. معالجة الكتاب: استخراج النص وتقسيمه إلى فقرات (تعديل لملفات PDF)\n",
        "def load_and_split_book(file_path):\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"لم يتم العثور على الملف {file_path}\")\n",
        "        return []\n",
        "    try:\n",
        "        with open(file_path, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page_num in range(len(pdf_reader.pages)):\n",
        "                page = pdf_reader.pages[page_num]\n",
        "                text += page.extract_text()\n",
        "            paragraphs = text.split('\\n\\n')  # تقسيم النص إلى فقرات بناءً على فاصل سطرين فارغين\n",
        "            return paragraphs\n",
        "    except Exception as e:\n",
        "         print(f\"حدث خطأ أثناء معالجة ملف PDF: {e}\")\n",
        "         return []\n",
        "\n",
        "# 2. تحميل النموذج instructor-large للتمثيل النصي\n",
        "print(\"جاري تحميل نموذج instructor-large...\")\n",
        "instructor_model = SentenceTransformer('hkunlp/instructor-large')\n",
        "print(\"تم تحميل نموذج instructor-large.\")\n",
        "\n",
        "# 3. إنشاء تمثيلات نصية (embeddings) للفقرات\n",
        "def generate_embeddings(paragraphs, model):\n",
        "    embeddings = model.encode(paragraphs, show_progress_bar=True)\n",
        "    return embeddings\n",
        "\n",
        "# 4. تحميل نموذج Llama-3.2-3B-Instruct للدردشة\n",
        "print(\"جاري تحميل نموذج Llama-3.2-3B-Instruct...\")\n",
        "llama_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
        "llama_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\", device_map=\"auto\", torch_dtype=\"float32\", low_cpu_mem_usage=True)\n",
        "print(\"تم تحميل نموذج Llama-3.2-3B-Instruct.\")\n",
        "\n",
        "# 5. وظيفة البحث عن الفقرات الأكثر صلة بالسؤال\n",
        "def search_relevant_paragraphs(query, embeddings, paragraphs, model, top_k=5):\n",
        "    query_embedding = model.encode(query)\n",
        "    similarities = torch.nn.functional.cosine_similarity(torch.tensor(query_embedding).unsqueeze(0), torch.tensor(embeddings))\n",
        "    top_indices = torch.topk(similarities, k=top_k).indices\n",
        "    return [paragraphs[i] for i in top_indices]\n",
        "\n",
        "# 6. وظيفة إنشاء الإجابة باستخدام Llama-3.2-3B-Instruct\n",
        "def generate_answer(query, context, tokenizer, model):\n",
        "    prompt = f\"Based on the following context, answer the question: Context: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(**inputs, max_length=200,do_sample=True, top_k=40, top_p=0.90)\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# 7. الواجهة الرئيسية للدردشة\n",
        "def chat_with_book(book_path):\n",
        "    paragraphs = load_and_split_book(book_path)\n",
        "\n",
        "    if not paragraphs:\n",
        "        print(\"لا يمكن بدء الدردشة، الرجاء التأكد من وجود الكتاب.\")\n",
        "        return\n",
        "\n",
        "    embeddings = generate_embeddings(paragraphs, instructor_model)\n",
        "\n",
        "    while True:\n",
        "        query = input(\"اطرح سؤالك (أو اكتب 'خروج' للخروج): \")\n",
        "        if query.lower() == 'خروج':\n",
        "            break\n",
        "\n",
        "        relevant_paragraphs = search_relevant_paragraphs(query, embeddings, paragraphs, instructor_model)\n",
        "        context = \" \".join(relevant_paragraphs)\n",
        "\n",
        "        answer = generate_answer(query, context, llama_tokenizer, llama_model)\n",
        "        print(\"الإجابة:\", answer)\n",
        "\n",
        "# بدء الدردشة\n",
        "if __name__ == \"__main__\":\n",
        "  chat_with_book(book_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648,
          "referenced_widgets": [
            "bc9eb13f92b8433cb055b3e4b5ce1fe4",
            "4cb679a86b614b0ea946ef0c7db67f41",
            "3ee4732a5e904a5eaccfd3aa87d3e0f2",
            "0d963fa80af24e3784fd739ebd3ca735",
            "db4e54c001134fbea91066cb3d7e8c26",
            "1b6486ad2a3548b5aaab4a227ebd0a39",
            "d76c4cb6dd354a20924afe0707341553",
            "aab997b84ab24a2abb5c307418c3189c",
            "cdecc071b24041e2b31fb37b5736e6aa",
            "06f1ef20c33e435c877747e618f6160b",
            "eeb91e2e53b8448196abcbbe2e9cb4ed",
            "0dfa05c1fa6d4958898e0e46d21591e9",
            "cdcb2ed66a284ccd8106e5cea0c61ac8",
            "39cf7bc34246475c81278cf1ae4c7bea",
            "99f90d9b07634363a0cbd48a671dc2b6",
            "953cb7f2c61b4657a9d56310891145e7",
            "ebbd8fcbe45c44229bf0880d4b4cbd70",
            "935b8777ec484f5ab355cfc6212f39dd",
            "0d426c49d26343ec8235b224eb7599ae",
            "a24b6dcc63bb4c3db78d10cca6709a1d",
            "566e0647edea4b108bc10af07cc48ca2",
            "58d3db21a70c48ff8981cc9471d1a22a"
          ]
        },
        "id": "UH2n_PSE89T0",
        "outputId": "3c018d26-fa70-480c-9e06-6b10bbde92de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "سيتم استخدام المعالج (CPU) نظرًا لعدم توفر معالج الرسوميات (GPU).\n",
            "جاري تحميل نموذج instructor-large...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تم تحميل نموذج instructor-large.\n",
            "جاري تحميل نموذج Llama-3.2-3B-Instruct...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc9eb13f92b8433cb055b3e4b5ce1fe4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تم تحميل نموذج Llama-3.2-3B-Instruct.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0dfa05c1fa6d4958898e0e46d21591e9"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "اطرح سؤالك (أو اكتب 'خروج' للخروج): Who is the hero of the story?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "selected index k out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9706c5937f88>\u001b[0m in \u001b[0;36m<cell line: 91>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;31m# بدء الدردشة\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m   \u001b[0mchat_with_book\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-9706c5937f88>\u001b[0m in \u001b[0;36mchat_with_book\u001b[0;34m(book_path)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mrelevant_paragraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_relevant_paragraphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparagraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstructor_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant_paragraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-9706c5937f88>\u001b[0m in \u001b[0;36msearch_relevant_paragraphs\u001b[0;34m(query, embeddings, paragraphs, model, top_k)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mquery_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mtop_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparagraphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: selected index k out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-r_o25i-GF-",
        "outputId": "d562c3be-3314-4c07-90e5-48c92ea71887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: read).\n",
            "The token `read` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `read`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تثبيت المكتبات اللازمة\n",
        "#!pip install transformers sentence-transformers accelerate torch PyPDF2\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pathlib import Path\n",
        "import os\n",
        "import PyPDF2\n",
        "\n",
        "# التحقق من توفر المعالج (CPU)\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"سيتم استخدام المعالج (CPU) نظرًا لعدم توفر معالج الرسوميات (GPU).\")\n",
        "else:\n",
        "    print(\"تم الكشف عن معالج الرسوميات (GPU)، ولكن سيتم استخدام المعالج (CPU) حسب طلبك.\")\n",
        "\n",
        "# تحديد مسار الكتاب (يمكنك تغييره)\n",
        "book_path = '/content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf'  # استبدل هذا بالمسار الفعلي للكتاب PDF الخاص بك\n",
        "\n",
        "# 1. معالجة الكتاب: استخراج النص وتقسيمه إلى فقرات (تعديل لملفات PDF)\n",
        "def load_and_split_book(file_path):\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"لم يتم العثور على الملف {file_path}\")\n",
        "        return []\n",
        "    try:\n",
        "        with open(file_path, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page_num in range(len(pdf_reader.pages)):\n",
        "                page = pdf_reader.pages[page_num]\n",
        "                text += page.extract_text()\n",
        "            paragraphs = text.split('\\n\\n')  # تقسيم النص إلى فقرات بناءً على فاصل سطرين فارغين\n",
        "            return paragraphs\n",
        "    except Exception as e:\n",
        "         print(f\"حدث خطأ أثناء معالجة ملف PDF: {e}\")\n",
        "         return []\n",
        "\n",
        "# 2. تحميل النموذج instructor-large للتمثيل النصي\n",
        "print(\"جاري تحميل نموذج instructor-large...\")\n",
        "instructor_model = SentenceTransformer('hkunlp/instructor-large', device='cpu')\n",
        "print(\"تم تحميل نموذج instructor-large.\")\n",
        "\n",
        "# 3. إنشاء تمثيلات نصية (embeddings) للفقرات\n",
        "def generate_embeddings(paragraphs, model):\n",
        "    embeddings = model.encode(paragraphs, show_progress_bar=True)\n",
        "    return embeddings\n",
        "\n",
        "# 4. تحميل نموذج Llama-3.2-3B-Instruct للدردشة\n",
        "print(\"جاري تحميل نموذج Llama-3.2-3B-Instruct...\")\n",
        "llama_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
        "llama_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\", device_map=\"auto\", torch_dtype=\"float32\", low_cpu_mem_usage=True)\n",
        "print(\"تم تحميل نموذج Llama-3.2-3B-Instruct.\")\n",
        "\n",
        "# 5. وظيفة البحث عن الفقرات الأكثر صلة بالسؤال (تعديل لحل الخطأ)\n",
        "def search_relevant_paragraphs(query, embeddings, paragraphs, model, top_k=5):\n",
        "    num_paragraphs = len(paragraphs)\n",
        "    if num_paragraphs == 0:\n",
        "      return [] # إرجاع قائمة فارغة إذا لم يكن هناك فقرات\n",
        "    if num_paragraphs < top_k:\n",
        "        top_k = num_paragraphs # تعديل قيمة k لتتناسب مع عدد الفقرات إذا كانت أقل منها\n",
        "\n",
        "    query_embedding = model.encode(query)\n",
        "    similarities = torch.nn.functional.cosine_similarity(torch.tensor(query_embedding).unsqueeze(0), torch.tensor(embeddings))\n",
        "    top_indices = torch.topk(similarities, k=top_k).indices\n",
        "    return [paragraphs[i] for i in top_indices]\n",
        "\n",
        "# 6. وظيفة إنشاء الإجابة باستخدام Llama-3.2-3B-Instruct\n",
        "def generate_answer(query, context, tokenizer, model):\n",
        "    prompt = f\"Based on the following context, answer the question: Context: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(**inputs, max_length=200,do_sample=True, top_k=50, top_p=0.95)\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# 7. الواجهة الرئيسية للدردشة\n",
        "def chat_with_book(book_path):\n",
        "    paragraphs = load_and_split_book(book_path)\n",
        "\n",
        "    if not paragraphs:\n",
        "        print(\"لا يمكن بدء الدردشة، الرجاء التأكد من وجود الكتاب.\")\n",
        "        return\n",
        "\n",
        "    embeddings = generate_embeddings(paragraphs, instructor_model)\n",
        "\n",
        "    while True:\n",
        "        query = input(\"اطرح سؤالك (أو اكتب 'خروج' للخروج): \")\n",
        "        if query.lower() == 'خروج':\n",
        "            break\n",
        "\n",
        "        relevant_paragraphs = search_relevant_paragraphs(query, embeddings, paragraphs, instructor_model)\n",
        "        context = \" \".join(relevant_paragraphs)\n",
        "\n",
        "        answer = generate_answer(query, context, llama_tokenizer, llama_model)\n",
        "        print(\"الإجابة:\", answer)\n",
        "\n",
        "# بدء الدردشة\n",
        "if __name__ == \"__main__\":\n",
        "  chat_with_book(book_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701,
          "referenced_widgets": [
            "3f063dc6867b4c2bb73796d6484d980e",
            "a1be486dad9942dda0c269e5fc3fb8ce",
            "307e0967f85d47e88811d3fe76f9dcc1",
            "7a7348d854f6458aab2c3cd9ba437657",
            "fc09df23c2364ed48427f20cdb581ef8",
            "e93ad8054d45498a9faf1c5f5f5b3396",
            "6853fb995be746b68ac85e8607e28ecc",
            "ad7e94ccc3864e62961ca39df29c4af2",
            "cfd2a42d2cf0436a87b34fbf3c99c607",
            "6978093ec3f24caeb343c280dc5e10be",
            "83a94e045a4c44f9be97117f6890e7a4",
            "d52eccb2d4cd4d8ea865da9921913ca9",
            "dfe5d11e9ad14ddf93e33b49906496aa",
            "11c96697459447f1bb57f4320e343583",
            "5059da18f88d42329967ce7055637a7b",
            "b216b7a739fc4755b580f3ae5126781f",
            "10a208597d2e4ca8ad57b783dc73acf0",
            "01642fc5555b4db5b2e170c204fa7453",
            "42271982fcc842d8af6cad2c2b9ce94c",
            "ede971df705b4329ac3886d790254fd9",
            "4b38511556d649e2bfa35121be27a771",
            "b17b343b8a3e40d0808be3bd1cb43218"
          ]
        },
        "id": "G8eZtpvn-H17",
        "outputId": "ce91c283-1674-461e-8b89-1ac0d03d4a58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "سيتم استخدام المعالج (CPU) نظرًا لعدم توفر معالج الرسوميات (GPU).\n",
            "جاري تحميل نموذج instructor-large...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تم تحميل نموذج instructor-large.\n",
            "جاري تحميل نموذج Llama-3.2-3B-Instruct...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f063dc6867b4c2bb73796d6484d980e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تم تحميل نموذج Llama-3.2-3B-Instruct.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d52eccb2d4cd4d8ea865da9921913ca9"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "اطرح سؤالك (أو اكتب 'خروج' للخروج): Who is the hero of the story?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input length of input_ids is 2585, but `max_length` is set to 200. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-26ed13605e6a>\u001b[0m in \u001b[0;36m<cell line: 97>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m# بدء الدردشة\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0mchat_with_book\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-26ed13605e6a>\u001b[0m in \u001b[0;36mchat_with_book\u001b[0;34m(book_path)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant_paragraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllama_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllama_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"الإجابة:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-26ed13605e6a>\u001b[0m in \u001b[0;36mgenerate_answer\u001b[0;34m(query, context, tokenizer, model)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Based on the following context, answer the question: Context: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2103\u001b[0m             \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_logits_to_keep\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_generated_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_default_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m         \u001b[0;31m# 7. Prepare the cache.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_validate_generated_length\u001b[0;34m(self, generation_config, input_ids_length, has_default_max_length)\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_ids_length\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m             \u001b[0minput_ids_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"decoder_input_ids\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1411\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1412\u001b[0m                 \u001b[0;34mf\"Input length of {input_ids_string} is {input_ids_length}, but `max_length` is set to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m                 \u001b[0;34mf\" {generation_config.max_length}. This can lead to unexpected behavior. You should consider\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input length of input_ids is 2585, but `max_length` is set to 200. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تثبيت المكتبات اللازمة\n",
        "#!pip install transformers sentence-transformers accelerate torch PyPDF2\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pathlib import Path\n",
        "import os\n",
        "import PyPDF2\n",
        "\n",
        "# التحقق من توفر المعالج (CPU)\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"سيتم استخدام المعالج (CPU) نظرًا لعدم توفر معالج الرسوميات (GPU).\")\n",
        "else:\n",
        "    print(\"تم الكشف عن معالج الرسوميات (GPU)، ولكن سيتم استخدام المعالج (CPU) حسب طلبك.\")\n",
        "\n",
        "# تحديد مسار الكتاب (يمكنك تغييره)\n",
        "book_path = '/content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf'  # استبدل هذا بالمسار الفعلي للكتاب PDF الخاص بك\n",
        "\n",
        "# 1. معالجة الكتاب: استخراج النص وتقسيمه إلى فقرات (تعديل لملفات PDF)\n",
        "def load_and_split_book(file_path):\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"لم يتم العثور على الملف {file_path}\")\n",
        "        return []\n",
        "    try:\n",
        "        with open(file_path, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page_num in range(len(pdf_reader.pages)):\n",
        "                page = pdf_reader.pages[page_num]\n",
        "                text += page.extract_text()\n",
        "            paragraphs = text.split('\\n\\n')  # تقسيم النص إلى فقرات بناءً على فاصل سطرين فارغين\n",
        "            return paragraphs\n",
        "    except Exception as e:\n",
        "         print(f\"حدث خطأ أثناء معالجة ملف PDF: {e}\")\n",
        "         return []\n",
        "\n",
        "# 2. تحميل النموذج instructor-large للتمثيل النصي\n",
        "print(\"جاري تحميل نموذج instructor-large...\")\n",
        "instructor_model = SentenceTransformer('hkunlp/instructor-large')\n",
        "print(\"تم تحميل نموذج instructor-large.\")\n",
        "\n",
        "# 3. إنشاء تمثيلات نصية (embeddings) للفقرات\n",
        "def generate_embeddings(paragraphs, model):\n",
        "    embeddings = model.encode(paragraphs, show_progress_bar=True)\n",
        "    return embeddings\n",
        "\n",
        "# 4. تحميل نموذج Llama-3.2-3B-Instruct للدردشة\n",
        "print(\"جاري تحميل نموذج Llama-3.2-3B-Instruct...\")\n",
        "llama_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
        "llama_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\", device_map=\"auto\", torch_dtype=\"float32\", low_cpu_mem_usage=True)\n",
        "print(\"تم تحميل نموذج Llama-3.2-3B-Instruct.\")\n",
        "\n",
        "# 5. وظيفة البحث عن الفقرات الأكثر صلة بالسؤال (تعديل لحل الخطأ)\n",
        "def search_relevant_paragraphs(query, embeddings, paragraphs, model, top_k=5):\n",
        "    num_paragraphs = len(paragraphs)\n",
        "    if num_paragraphs == 0:\n",
        "        return []  # إرجاع قائمة فارغة إذا لم يكن هناك فقرات\n",
        "    if num_paragraphs < top_k:\n",
        "        top_k = num_paragraphs  # تعديل قيمة k لتتناسب مع عدد الفقرات إذا كانت أقل منها\n",
        "\n",
        "    query_embedding = model.encode(query)\n",
        "    similarities = torch.nn.functional.cosine_similarity(torch.tensor(query_embedding).unsqueeze(0), torch.tensor(embeddings))\n",
        "    top_indices = torch.topk(similarities, k=top_k).indices\n",
        "    return [paragraphs[i] for i in top_indices]\n",
        "\n",
        "# 6. وظيفة إنشاء الإجابة باستخدام Llama-3.2-3B-Instruct (تعديل لاستخدام max_new_tokens)\n",
        "def generate_answer(query, context, tokenizer, model):\n",
        "    prompt = f\"Based on the following context, answer the question: Context: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=300, do_sample=True, top_k=50, top_p=0.95)\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# 7. الواجهة الرئيسية للدردشة\n",
        "def chat_with_book(book_path):\n",
        "    paragraphs = load_and_split_book(book_path)\n",
        "\n",
        "    if not paragraphs:\n",
        "        print(\"لا يمكن بدء الدردشة، الرجاء التأكد من وجود الكتاب.\")\n",
        "        return\n",
        "\n",
        "    embeddings = generate_embeddings(paragraphs, instructor_model)\n",
        "\n",
        "    while True:\n",
        "        query = input(\"اطرح سؤالك (أو اكتب 'خروج' للخروج): \")\n",
        "        if query.lower() == 'خروج':\n",
        "            break\n",
        "\n",
        "        relevant_paragraphs = search_relevant_paragraphs(query, embeddings, paragraphs, instructor_model)\n",
        "        context = \" \".join(relevant_paragraphs)\n",
        "\n",
        "        answer = generate_answer(query, context, llama_tokenizer, llama_model)\n",
        "        print(\"الإجابة:\", answer)\n",
        "\n",
        "# بدء الدردشة\n",
        "if __name__ == \"__main__\":\n",
        "    chat_with_book(book_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344,
          "referenced_widgets": [
            "b8228f7aeff040b1b36a5ad070c2f7c6",
            "129c2435fdeb409eb738b684ffc33068",
            "de2e989c35ef4ba091dd56877ca85c98",
            "12fb0729d2d74bfbb313dcb396577ef7",
            "9311318f49a64caa93a41931576baf14",
            "c571e858b5ab4063aaf83063dabbb176",
            "e93c6361e03440df9ff462f8882fa265",
            "1281f11112bb459a83217d14d600b589",
            "1beb21dd56534c54b0c637c4a95fd67e",
            "518ee95ba92a473791c05c27d7bbab6b",
            "a7796b0926c6492ab43c23071062c39b",
            "326a4c5fe11645efa98ef3f75c17e7fa",
            "2c26f4c4459b49ad8ce4f854a025dc59",
            "5c8479ea12d6445cb7263d262a77af5a",
            "c59d8f67ce03451f951130bdcd1a0a6a",
            "a625714f59b44b78af5c0c5bbc67cfe2",
            "6c2cc66d0b754831a0d9b601e466181f",
            "ff0fef2bbc5d41ee8f5af9304992ba23",
            "539f4c4055f34c7eb903aad8da0aa1b7",
            "27e17d82e0554156be840e79a87b38aa",
            "c0abce276ce846019de78866d55b0624",
            "8a271c36b9194d9185f4189c51f3b3e2"
          ]
        },
        "id": "o6yTVnLMB_Y_",
        "outputId": "7ef8673e-4adc-48c8-b6f3-0e45fc0db55f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "سيتم استخدام المعالج (CPU) نظرًا لعدم توفر معالج الرسوميات (GPU).\n",
            "جاري تحميل نموذج instructor-large...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تم تحميل نموذج instructor-large.\n",
            "جاري تحميل نموذج Llama-3.2-3B-Instruct...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8228f7aeff040b1b36a5ad070c2f7c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تم تحميل نموذج Llama-3.2-3B-Instruct.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "326a4c5fe11645efa98ef3f75c17e7fa"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "اطرح سؤالك (أو اكتب 'خروج' للخروج): Who is the hero of the story?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تثبيت المكتبات اللازمة\n",
        "#!pip install transformers sentence-transformers accelerate torch PyPDF2\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pathlib import Path\n",
        "import os\n",
        "import PyPDF2\n",
        "\n",
        "# التحقق من توفر المعالج (CPU)\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"سيتم استخدام المعالج (CPU) نظرًا لعدم توفر معالج الرسوميات (GPU).\")\n",
        "else:\n",
        "    print(\"تم الكشف عن معالج الرسوميات (GPU)، ولكن سيتم استخدام المعالج (CPU) حسب طلبك.\")\n",
        "\n",
        "# تحديد مسار الكتاب (يمكنك تغييره)\n",
        "book_path = '/content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf'  # استبدل هذا بالمسار الفعلي للكتاب PDF الخاص بك\n",
        "\n",
        "# 1. معالجة الكتاب: استخراج النص وتقسيمه إلى فقرات (تعديل لملفات PDF)\n",
        "def load_and_split_book(file_path):\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"لم يتم العثور على الملف {file_path}\")\n",
        "        return []\n",
        "    try:\n",
        "        with open(file_path, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page_num in range(len(pdf_reader.pages)):\n",
        "                page = pdf_reader.pages[page_num]\n",
        "                text += page.extract_text()\n",
        "            paragraphs = text.split('\\n\\n')  # تقسيم النص إلى فقرات بناءً على فاصل سطرين فارغين\n",
        "            return paragraphs\n",
        "    except Exception as e:\n",
        "         print(f\"حدث خطأ أثناء معالجة ملف PDF: {e}\")\n",
        "         return []\n",
        "\n",
        "# 2. تحميل النموذج instructor-large للتمثيل النصي\n",
        "print(\"جاري تحميل نموذج instructor-large...\")\n",
        "instructor_model = SentenceTransformer('hkunlp/instructor-large')\n",
        "print(\"تم تحميل نموذج instructor-large.\")\n",
        "\n",
        "# 3. إنشاء تمثيلات نصية (embeddings) للفقرات\n",
        "def generate_embeddings(paragraphs, model):\n",
        "    embeddings = model.encode(paragraphs, show_progress_bar=True)\n",
        "    return embeddings\n",
        "\n",
        "# 4. تحميل نموذج Llama-3.2-3B-Instruct للدردشة\n",
        "print(\"جاري تحميل نموذج Llama-3.2-3B-Instruct...\")\n",
        "llama_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
        "llama_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\", device_map=\"auto\", torch_dtype=\"float32\", low_cpu_mem_usage=True)\n",
        "print(\"تم تحميل نموذج Llama-3.2-3B-Instruct.\")\n",
        "\n",
        "# 5. وظيفة البحث عن الفقرات الأكثر صلة بالسؤال (تعديل لحل الخطأ)\n",
        "def search_relevant_paragraphs(query, embeddings, paragraphs, model, top_k=5):\n",
        "    num_paragraphs = len(paragraphs)\n",
        "    if num_paragraphs == 0:\n",
        "        return []  # إرجاع قائمة فارغة إذا لم يكن هناك فقرات\n",
        "    if num_paragraphs < top_k:\n",
        "        top_k = num_paragraphs  # تعديل قيمة k لتتناسب مع عدد الفقرات إذا كانت أقل منها\n",
        "\n",
        "    query_embedding = model.encode(query)\n",
        "    similarities = torch.nn.functional.cosine_similarity(torch.tensor(query_embedding).unsqueeze(0), torch.tensor(embeddings))\n",
        "    top_indices = torch.topk(similarities, k=top_k).indices\n",
        "    return [paragraphs[i] for i in top_indices]\n",
        "\n",
        "# 6. وظيفة إنشاء الإجابة باستخدام Llama-3.2-3B-Instruct (تعديل لاستخدام max_new_tokens)\n",
        "def generate_answer(query, context, tokenizer, model):\n",
        "    prompt = f\"Based on the following context, answer the question: Context: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=30, do_sample=True, top_k=40, top_p=0.85)\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# 7. الواجهة الرئيسية للدردشة\n",
        "def chat_with_book(book_path):\n",
        "    paragraphs = load_and_split_book(book_path)\n",
        "\n",
        "    if not paragraphs:\n",
        "        print(\"لا يمكن بدء الدردشة، الرجاء التأكد من وجود الكتاب.\")\n",
        "        return\n",
        "\n",
        "    embeddings = generate_embeddings(paragraphs, instructor_model)\n",
        "\n",
        "    while True:\n",
        "        query = input(\"اطرح سؤالك (أو اكتب 'خروج' للخروج): \")\n",
        "        if query.lower() == 'خروج':\n",
        "            break\n",
        "\n",
        "        relevant_paragraphs = search_relevant_paragraphs(query, embeddings, paragraphs, instructor_model)\n",
        "        context = \" \".join(relevant_paragraphs)\n",
        "\n",
        "        answer = generate_answer(query, context, llama_tokenizer, llama_model)\n",
        "        print(\"الإجابة:\", answer)\n",
        "\n",
        "# بدء الدردشة\n",
        "if __name__ == \"__main__\":\n",
        "    chat_with_book(book_path)"
      ],
      "metadata": {
        "id": "ljl-uQwPGS_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تثبيت المكتبات اللازمة\n",
        "#!pip install transformers sentence-transformers accelerate torch PyPDF2\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pathlib import Path\n",
        "import os\n",
        "import PyPDF2\n",
        "\n",
        "# التحقق من توفر المعالج (CPU)\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"سيتم استخدام المعالج (CPU) نظرًا لعدم توفر معالج الرسوميات (GPU).\")\n",
        "else:\n",
        "    print(\"تم الكشف عن معالج الرسوميات (GPU)، ولكن سيتم استخدام المعالج (CPU) حسب طلبك.\")\n",
        "\n",
        "# تحديد مسار الكتاب (يمكنك تغييره)\n",
        "book_path = '/content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf'  # استبدل هذا بالمسار الفعلي للكتاب PDF الخاص بك\n",
        "\n",
        "# 1. معالجة الكتاب: استخراج النص وتقسيمه إلى فقرات (تعديل لملفات PDF)\n",
        "def load_and_split_book(file_path):\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"لم يتم العثور على الملف {file_path}\")\n",
        "        return []\n",
        "    try:\n",
        "        with open(file_path, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page_num in range(len(pdf_reader.pages)):\n",
        "                page = pdf_reader.pages[page_num]\n",
        "                text += page.extract_text()\n",
        "            paragraphs = text.split('\\n\\n')  # تقسيم النص إلى فقرات بناءً على فاصل سطرين فارغين\n",
        "            return paragraphs\n",
        "    except Exception as e:\n",
        "         print(f\"حدث خطأ أثناء معالجة ملف PDF: {e}\")\n",
        "         return []\n",
        "\n",
        "# 2. تحميل النموذج instructor-large للتمثيل النصي\n",
        "print(\"جاري تحميل نموذج instructor-large...\")\n",
        "instructor_model = SentenceTransformer('hkunlp/instructor-large', device='cpu')\n",
        "print(\"تم تحميل نموذج instructor-large.\")\n",
        "\n",
        "# 3. إنشاء تمثيلات نصية (embeddings) للفقرات\n",
        "def generate_embeddings(paragraphs, model):\n",
        "    embeddings = model.encode(paragraphs, show_progress_bar=True)\n",
        "    return embeddings\n",
        "\n",
        "# 4. تحميل نموذج Llama-3.2-3B-Instruct للدردشة (نموذج أصغر)\n",
        "print(\"جاري تحميل نموذج Llama-3.2-3B-Instruct...\")\n",
        "llama_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
        "llama_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\", device_map=\"auto\", torch_dtype=\"bfloat32\", low_cpu_mem_usage=True)\n",
        "print(\"تم تحميل نموذج Llama-3.2-3B-Instruct.\")\n",
        "\n",
        "# 5. وظيفة البحث عن الفقرات الأكثر صلة بالسؤال (تعديل لحل الخطأ)\n",
        "def search_relevant_paragraphs(query, embeddings, paragraphs, model, top_k=5):\n",
        "    num_paragraphs = len(paragraphs)\n",
        "    if num_paragraphs == 0:\n",
        "        return []  # إرجاع قائمة فارغة إذا لم يكن هناك فقرات\n",
        "    if num_paragraphs < top_k:\n",
        "        top_k = num_paragraphs  # تعديل قيمة k لتتناسب مع عدد الفقرات إذا كانت أقل منها\n",
        "\n",
        "    query_embedding = model.encode(query)\n",
        "    similarities = torch.nn.functional.cosine_similarity(torch.tensor(query_embedding).unsqueeze(0), torch.tensor(embeddings))\n",
        "    top_indices = torch.topk(similarities, k=top_k).indices\n",
        "    return [paragraphs[i] for i in top_indices]\n",
        "\n",
        "# 6. وظيفة إنشاء الإجابة باستخدام Llama-3.2-3B-Instruct (تعديل لاستخدام max_new_tokens)\n",
        "def generate_answer(query, context, tokenizer, model):\n",
        "    prompt = f\"Based on the following context, answer the question: Context: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=30, do_sample=True, top_k=40, top_p=0.9)\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# 7. الواجهة الرئيسية للدردشة\n",
        "def chat_with_book(book_path):\n",
        "    paragraphs = load_and_split_book(book_path)\n",
        "\n",
        "    if not paragraphs:\n",
        "        print(\"لا يمكن بدء الدردشة، الرجاء التأكد من وجود الكتاب.\")\n",
        "        return\n",
        "\n",
        "    embeddings = generate_embeddings(paragraphs, instructor_model)\n",
        "\n",
        "    while True:\n",
        "        query = input(\"اطرح سؤالك (أو اكتب 'خروج' للخروج): \")\n",
        "        if query.lower() == 'خروج':\n",
        "            break\n",
        "\n",
        "        relevant_paragraphs = search_relevant_paragraphs(query, embeddings, paragraphs, instructor_model)\n",
        "        context = \" \".join(relevant_paragraphs)\n",
        "\n",
        "        answer = generate_answer(query, context, llama_tokenizer, llama_model)\n",
        "        print(\"الإجابة:\", answer)\n",
        "\n",
        "# بدء الدردشة\n",
        "if __name__ == \"__main__\":\n",
        "    chat_with_book(book_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "r6MF2EK4Gdqw",
        "outputId": "ad230d23-2f5d-42c7-9015-75f0c951ef4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "partially initialized module 'torch' has no attribute 'nn' (most likely due to a circular import)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-008ccf188f35>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#!pip install transformers sentence-transformers accelerate torch PyPDF2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2057\u001b[0m )\n\u001b[1;32m   2058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m from torch import (\n\u001b[0m\u001b[1;32m   2060\u001b[0m     \u001b[0m__config__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m__config__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m     \u001b[0m__future__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m__future__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \"\"\"\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlr_scheduler\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mswa_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adafactor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdafactor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mAdafactor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madadelta\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdadelta\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mAdadelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0m_global_optimizer_pre_hooks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGlobalOptimizerPreHook\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0m_global_optimizer_post_hooks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGlobalOptimizerPostHook\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0m_foreach_supported_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'torch' has no attribute 'nn' (most likely due to a circular import)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch -y\n",
        "!pip install torch torchvision torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CcP3XjlzG1mP",
        "outputId": "a309a036-dc8e-42a4-bdad-166a8f355a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.5.1+cu121\n",
            "Uninstalling torch-2.5.1+cu121:\n",
            "  Successfully uninstalled torch-2.5.1+cu121\n",
            "Collecting torch\n",
            "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n",
            "    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 torch-2.5.1 triton-3.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchgen"
                ]
              },
              "id": "5876458666194c4dbadb11001da8aeac"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تثبيت وإعادة تثبيت PyTorch\n",
        "!pip uninstall torch -y\n",
        "!pip install torch torchvision torchaudio\n",
        "\n",
        "# تثبيت المكتبات اللازمة\n",
        "!pip install transformers sentence-transformers accelerate PyPDF2"
      ],
      "metadata": {
        "id": "eSK-yhCuHcyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "استمر اكتر من نص ساعة"
      ],
      "metadata": {
        "id": "QqPPpqahRc0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F  # استيراد F من torch.nn.functional\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pathlib import Path\n",
        "import os\n",
        "import PyPDF2\n",
        "\n",
        "# التحقق من إصدار PyTorch\n",
        "print(\"إصدار PyTorch:\", torch.__version__)\n",
        "\n",
        "# التحقق من توفر المعالج (CPU)\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"سيتم استخدام المعالج (CPU) نظرًا لعدم توفر معالج الرسوميات (GPU).\")\n",
        "else:\n",
        "    print(\"تم الكشف عن معالج الرسوميات (GPU)، ولكن سيتم استخدام المعالج (CPU) حسب طلبك.\")\n",
        "\n",
        "# تحديد مسار الكتاب (يمكنك تغييره)\n",
        "book_path = '/content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf'  # استبدل هذا بالمسار الفعلي للكتاب PDF الخاص بك\n",
        "\n",
        "# 1. معالجة الكتاب: استخراج النص وتقسيمه إلى فقرات (تعديل لملفات PDF)\n",
        "def load_and_split_book(file_path):\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"لم يتم العثور على الملف {file_path}\")\n",
        "        return []\n",
        "    try:\n",
        "        with open(file_path, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page_num in range(len(pdf_reader.pages)):\n",
        "                page = pdf_reader.pages[page_num]\n",
        "                text += page.extract_text()\n",
        "            paragraphs = text.split('\\n\\n')  # تقسيم النص إلى فقرات بناءً على فاصل سطرين فارغين\n",
        "            return paragraphs\n",
        "    except Exception as e:\n",
        "         print(f\"حدث خطأ أثناء معالجة ملف PDF: {e}\")\n",
        "         return []\n",
        "\n",
        "# 2. تحميل النموذج instructor-large للتمثيل النصي\n",
        "print(\"جاري تحميل نموذج instructor-large...\")\n",
        "instructor_model = SentenceTransformer('hkunlp/instructor-large', device='cpu')\n",
        "print(\"تم تحميل نموذج instructor-large.\")\n",
        "\n",
        "# 3. إنشاء تمثيلات نصية (embeddings) للفقرات\n",
        "def generate_embeddings(paragraphs, model):\n",
        "    embeddings = model.encode(paragraphs, show_progress_bar=True)\n",
        "    return embeddings\n",
        "\n",
        "# 4. تحميل نموذج Llama-3.2-3B-Instruct للدردشة (نموذج أصغر)\n",
        "print(\"جاري تحميل نموذج Llama-3.2-3B-Instruct...\")\n",
        "llama_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
        "llama_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\", device_map=\"auto\", torch_dtype=\"auto\", low_cpu_mem_usage=True)\n",
        "print(\"تم تحميل نموذج Llama-3.2-3B-Instruct.\")\n",
        "print(\"تم تحميل نموذج Llama-3.2-3B-Instruct.\")\n",
        "\n",
        "# 5. وظيفة البحث عن الفقرات الأكثر صلة بالسؤال (تعديل لحل الخطأ)\n",
        "def search_relevant_paragraphs(query, embeddings, paragraphs, model, top_k=5):\n",
        "    num_paragraphs = len(paragraphs)\n",
        "    if num_paragraphs == 0:\n",
        "        return []  # إرجاع قائمة فارغة إذا لم يكن هناك فقرات\n",
        "    if num_paragraphs < top_k:\n",
        "        top_k = num_paragraphs  # تعديل قيمة k لتتناسب مع عدد الفقرات إذا كانت أقل منها\n",
        "\n",
        "    query_embedding = model.encode(query)\n",
        "    similarities = F.cosine_similarity(torch.tensor(query_embedding).unsqueeze(0), torch.tensor(embeddings)) # استخدم F بدلاً من torch.nn.functional\n",
        "    top_indices = torch.topk(similarities, k=top_k).indices\n",
        "    return [paragraphs[i] for i in top_indices]\n",
        "\n",
        "# 6. وظيفة إنشاء الإجابة باستخدام Llama-3.2-3B-Instruct (تعديل لاستخدام max_new_tokens)\n",
        "def generate_answer(query, context, tokenizer, model):\n",
        "    prompt = f\"Based on the following context, answer the question: Context: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=30, do_sample=True, top_k=40, top_p=0.90)\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# 7. الواجهة الرئيسية للدردشة\n",
        "def chat_with_book(book_path):\n",
        "    paragraphs = load_and_split_book(book_path)\n",
        "\n",
        "    if not paragraphs:\n",
        "        print(\"لا يمكن بدء الدردشة، الرجاء التأكد من وجود الكتاب.\")\n",
        "        return\n",
        "\n",
        "    embeddings = generate_embeddings(paragraphs, instructor_model)\n",
        "\n",
        "    while True:\n",
        "        query = input(\"اطرح سؤالك (أو اكتب 'خروج' للخروج): \")\n",
        "        if query.lower() == 'خروج':\n",
        "            break\n",
        "\n",
        "        relevant_paragraphs = search_relevant_paragraphs(query, embeddings, paragraphs, instructor_model)\n",
        "        context = \" \".join(relevant_paragraphs)\n",
        "\n",
        "        answer = generate_answer(query, context, llama_tokenizer, llama_model)\n",
        "        print(\"الإجابة:\", answer)\n",
        "\n",
        "# بدء الدردشة\n",
        "if __name__ == \"__main__\":\n",
        "    chat_with_book(book_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237,
          "referenced_widgets": [
            "54ed978665d340e78d67857952c45680",
            "e9ea34ac41d74f49996e8250e1352033",
            "10d3cd87c4364d9a9c2c73627dccb211",
            "ffced1e714c24d2d926cd5d2bc55d900",
            "8c7f463517ac4293a7a14beba8e112fd",
            "32e28bcef1d642e4a79e32afe2602abb",
            "9ed0f1345bfb4eab937d1a919b384318",
            "93d31cfac02b4d4f808d90f554a39676",
            "98ffbbbf3d7346d6b9aa4b8d097e88e3",
            "43169a51900840938fdb64f89379a995",
            "30ba3d958ac847889523432a0775cf0d",
            "c1666aefd01747d99fd93126984bd05c",
            "349e252d6b5246e1bd40e407d05dffe7",
            "54c8682283f1406384b46af858e19e93",
            "d8ff0bd46500402d9b3c0e2b992941ce",
            "c35117e515554b6a93bedd72e05fd234",
            "948bab051f8f48709f47e2155d3e8704",
            "fdc4c5c044d146a6bc7bf902dbcd400f",
            "07ca2c8348ec470f9fbe89f390588e52",
            "12e0e628936246e3b03fab9adf98afd0",
            "25dfef57085a4342b48256e8dda0607d",
            "cffdccd0f2324512984f67778a1772bf"
          ]
        },
        "id": "fnWdlJKdHR7v",
        "outputId": "8b893a76-0a4e-4325-e313-cd49ccc60aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "إصدار PyTorch: 2.5.1+cu124\n",
            "سيتم استخدام المعالج (CPU) نظرًا لعدم توفر معالج الرسوميات (GPU).\n",
            "جاري تحميل نموذج instructor-large...\n",
            "تم تحميل نموذج instructor-large.\n",
            "جاري تحميل نموذج Llama-3.2-3B-Instruct...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54ed978665d340e78d67857952c45680"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تم تحميل نموذج Llama-3.2-3B-Instruct.\n",
            "تم تحميل نموذج Llama-3.2-3B-Instruct.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1666aefd01747d99fd93126984bd05c"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "اطرح سؤالك (أو اكتب 'خروج' للخروج): Who is the hero of the story?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "aشغال مدة كبيرة"
      ],
      "metadata": {
        "id": "HmEAFVlQWhwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pathlib import Path\n",
        "import os\n",
        "import PyPDF2\n",
        "\n",
        "# التحقق من إصدار PyTorch\n",
        "print(\"إصدار PyTorch:\", torch.__version__)\n",
        "\n",
        "# التحقق من توفر المعالج (CPU)\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"سيتم استخدام المعالج (CPU) نظرًا لعدم توفر معالج الرسوميات (GPU).\")\n",
        "else:\n",
        "    print(\"تم الكشف عن معالج الرسوميات (GPU)، ولكن سيتم استخدام المعالج (CPU) حسب طلبك.\")\n",
        "\n",
        "# تحديد مسار الكتاب (يمكنك تغييره)\n",
        "book_path = '/content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf'  # استبدل هذا بالمسار الفعلي للكتاب PDF الخاص بك\n",
        "\n",
        "# 1. معالجة الكتاب: استخراج النص وتقسيمه إلى فقرات (تعديل لملفات PDF)\n",
        "def load_and_split_book(file_path):\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"لم يتم العثور على الملف {file_path}\")\n",
        "        return []\n",
        "    try:\n",
        "        with open(file_path, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page_num in range(len(pdf_reader.pages)):\n",
        "                page = pdf_reader.pages[page_num]\n",
        "                text += page.extract_text()\n",
        "            paragraphs = text.split('\\n\\n')  # تقسيم النص إلى فقرات بناءً على فاصل سطرين فارغين\n",
        "            return paragraphs\n",
        "    except Exception as e:\n",
        "         print(f\"حدث خطأ أثناء معالجة ملف PDF: {e}\")\n",
        "         return []\n",
        "\n",
        "# 2. تحميل النموذج instructor-large للتمثيل النصي\n",
        "print(\"جاري تحميل نموذج instructor-large...\")\n",
        "instructor_model = SentenceTransformer('hkunlp/instructor-large', device='cpu')\n",
        "print(\"تم تحميل نموذج instructor-large.\")\n",
        "\n",
        "# 3. إنشاء تمثيلات نصية (embeddings) للفقرات\n",
        "def generate_embeddings(paragraphs, model):\n",
        "    embeddings = model.encode(paragraphs, show_progress_bar=True)\n",
        "    return embeddings\n",
        "\n",
        "# 4. تحميل نموذج Llama-3.2-3B-Instruct للدردشة (نموذج أصغر)\n",
        "print(\"جاري تحميل نموذج Llama-3.2-3B-Instruct...\")\n",
        "llama_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
        "llama_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\", device_map=\"auto\", torch_dtype=torch.float16, low_cpu_mem_usage=True) # تحميل النموذج بدقة float16\n",
        "print(\"تم تحميل نموذج Llama-3.2-3B-Instruct.\")\n",
        "\n",
        "# 5. وظيفة البحث عن الفقرات الأكثر صلة بالسؤال (تعديل لحل الخطأ)\n",
        "def search_relevant_paragraphs(query, embeddings, paragraphs, model, top_k=3): # تقليل top_k هنا\n",
        "    num_paragraphs = len(paragraphs)\n",
        "    if num_paragraphs == 0:\n",
        "        return []  # إرجاع قائمة فارغة إذا لم يكن هناك فقرات\n",
        "    if num_paragraphs < top_k:\n",
        "        top_k = num_paragraphs  # تعديل قيمة k لتتناسب مع عدد الفقرات إذا كانت أقل منها\n",
        "\n",
        "    query_embedding = model.encode(query)\n",
        "    similarities = F.cosine_similarity(torch.tensor(query_embedding).unsqueeze(0), torch.tensor(embeddings))\n",
        "    top_indices = torch.topk(similarities, k=top_k).indices\n",
        "    return [paragraphs[i] for i in top_indices]\n",
        "\n",
        "# 6. وظيفة إنشاء الإجابة باستخدام Llama-3.2-3B-Instruct (تعديل لاستخدام max_new_tokens)\n",
        "def generate_answer(query, context, tokenizer, model):\n",
        "    prompt = f\"Based on the following context, answer the question: Context: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    max_context_length = 512 # تحديد الطول الأقصى للسياق\n",
        "    if len(inputs['input_ids'][0]) > max_context_length:\n",
        "      inputs['input_ids'] = inputs['input_ids'][:, :max_context_length] # قطع السياق إذا تجاوز الحد الأقصى\n",
        "      inputs['attention_mask'] = inputs['attention_mask'][:, :max_context_length]\n",
        "    outputs = model.generate(**inputs, max_new_tokens=50, do_sample=False, top_k=30, top_p=0.85) # تعطيل do_sample, تقليل max_new_tokens , وتقليل top_k و top_p\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# 7. الواجهة الرئيسية للدردشة\n",
        "def chat_with_book(book_path):\n",
        "    paragraphs = load_and_split_book(book_path)\n",
        "\n",
        "    if not paragraphs:\n",
        "        print(\"لا يمكن بدء الدردشة، الرجاء التأكد من وجود الكتاب.\")\n",
        "        return\n",
        "\n",
        "    embeddings = generate_embeddings(paragraphs, instructor_model)\n",
        "\n",
        "    while True:\n",
        "        query = input(\"اطرح سؤالك (أو اكتب 'خروج' للخروج): \")\n",
        "        if query.lower() == 'خروج':\n",
        "            break\n",
        "\n",
        "        relevant_paragraphs = search_relevant_paragraphs(query, embeddings, paragraphs, instructor_model)\n",
        "        context = \" \".join(relevant_paragraphs)\n",
        "\n",
        "        answer = generate_answer(query, context, llama_tokenizer, llama_model)\n",
        "        print(\"الإجابة:\", answer)\n",
        "\n",
        "# بدء الدردشة\n",
        "if __name__ == \"__main__\":\n",
        "    chat_with_book(book_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448,
          "referenced_widgets": [
            "420f8db4207c4ff79061f60e217a5e7a",
            "08cc5d688fdd48b1853046984dafee54",
            "242cb074c86c4bfa9b6e5060b8b94c78",
            "db5593d1401e423585bf0203f55c4b2a",
            "2ec5ca425e534e9da82c99cf419f6c95",
            "1a3d4de601224d238bc62739b403a642",
            "715b8b93f7d54c14b1d226ed5f9b9cd5",
            "f5feca1fccc644a297fc3a3ba67118a1",
            "420ba6d451bc4f2387fbbee3724286f7",
            "7e1049f4e76e43d09a06c86251a96fb2",
            "56f93dda953e4653826dab2cb314edee",
            "b5f2a6c837c0490c9f96d0915b496157",
            "81e86a14db9e4438bd9122d3e09d8915",
            "d9fffc8f28d64a69a5e0b68c3cff99b1",
            "cc316e535cfc4d4ea82cda03afff661f",
            "a509041161ad4782b4422e5a6c90758e",
            "0ad4ac8b5d324468b0be4c88e0687df7",
            "e2620cdca97a4190be2dbd904bdce81d",
            "7e4fbb0b90454f1c9aab133712d94dad",
            "3e871404b3cb44d8ae82d02224650bdc",
            "da5e9fa296b04fd49be190bb04798fda",
            "f7766a8a4fb943e4bcc1875de14c436b"
          ]
        },
        "id": "nniB1nIGRJ_l",
        "outputId": "f03dfbdd-0a88-4e26-a712-8524d943a8fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "إصدار PyTorch: 2.5.1+cu124\n",
            "سيتم استخدام المعالج (CPU) نظرًا لعدم توفر معالج الرسوميات (GPU).\n",
            "جاري تحميل نموذج instructor-large...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تم تحميل نموذج instructor-large.\n",
            "جاري تحميل نموذج Llama-3.2-3B-Instruct...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "420f8db4207c4ff79061f60e217a5e7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تم تحميل نموذج Llama-3.2-3B-Instruct.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5f2a6c837c0490c9f96d0915b496157"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "اطرح سؤالك (أو اكتب 'خروج' للخروج): Who is the hero of the story?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.85` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:650: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `30` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
        "  warnings.warn(\n",
        "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.85` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
        "  warnings.warn(\n",
        "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:650: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `30` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
        "  warnings.warn(\n",
        "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation."
      ],
      "metadata": {
        "id": "ZIEwbXgqSRr8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QJf9K1dkX1AA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install InstructorEmbedding"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mFrguuyX1_0",
        "outputId": "31ab3898-d2f4-44cd-d4d0-8938b05d80f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting InstructorEmbedding\n",
            "  Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl.metadata (20 kB)\n",
            "Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: InstructorEmbedding\n",
            "Successfully installed InstructorEmbedding-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3RzXITRAR0SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YWY1Q4cnYQnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WBmTPgc3YQhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install pymupdf"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDOHC9F3arhM",
        "outputId": "40b3f932-0bef-40bd-86ef-55d32406f322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/mjanputra/chatPDF"
      ],
      "metadata": {
        "id": "eeXCXeyHbZ7h"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FGecia87bjFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbgdQI0rqYPL",
        "outputId": "d18fcdb3-ba2f-454e-99a8-50ff2811e1fb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.27.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.12.14)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfPHd0GQquyT",
        "outputId": "b35216e8-c32a-4cb1-9049-eca2de6501e1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: read).\n",
            "The token `read` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `read`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "شغال سريع على الفيجا"
      ],
      "metadata": {
        "id": "Nh6_aFTZwTi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from PyPDF2 import PdfReader\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Setup device (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Running on: {device}\")\n",
        "\n",
        "# Load embedding and language models\n",
        "embedding_model = SentenceTransformer('hkunlp/instructor-large', device=device)\n",
        "language_model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(language_model_name)\n",
        "language_model = AutoModelForCausalLM.from_pretrained(\n",
        "   language_model_name,\n",
        "   device_map=\"auto\",\n",
        "   torch_dtype=torch.float16\n",
        ").to(device)\n",
        "\n",
        "# Clean text\n",
        "def clean_text(text):\n",
        "   text = text.replace('\\n', ' ')\n",
        "   text = ' '.join(text.split())\n",
        "   return text\n",
        "\n",
        "# Extract text from PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "   reader = PdfReader(pdf_path)\n",
        "   text = \"\"\n",
        "   for page in reader.pages:\n",
        "       text += page.extract_text()\n",
        "   return clean_text(text)\n",
        "\n",
        "# Split text into chunks\n",
        "def split_text(text, chunk_size=300):\n",
        "   sentences = text.split('.')\n",
        "   chunks = []\n",
        "   current_chunk = \"\"\n",
        "   for sentence in sentences:\n",
        "       if len(current_chunk) + len(sentence) < chunk_size:\n",
        "           current_chunk += sentence + \".\"\n",
        "       else:\n",
        "           chunks.append(current_chunk)\n",
        "           current_chunk = sentence + \".\"\n",
        "   if current_chunk:\n",
        "       chunks.append(current_chunk)\n",
        "   return chunks\n",
        "\n",
        "# Create embeddings\n",
        "def create_embeddings(chunks):\n",
        "   return embedding_model.encode(chunks, convert_to_tensor=True)\n",
        "\n",
        "# Search relevant chunks\n",
        "def search_relevant_chunks(question, chunks, embeddings, top_k=3):\n",
        "   question_embedding = embedding_model.encode(question, convert_to_tensor=True)\n",
        "   similarities = torch.matmul(embeddings, question_embedding.T).cpu().numpy()\n",
        "   top_indices = np.argsort(similarities, axis=0)[-top_k:][::-1]\n",
        "   return [chunks[idx] for idx in top_indices.flatten()]\n",
        "\n",
        "# Create prompt\n",
        "def create_prompt(relevant_chunks, question):\n",
        "   context = \"\\n\".join(relevant_chunks)\n",
        "   return f\"\"\"Use the following information from the book to answer the question. If the information is not in the provided text, say so clearly.\n",
        "\n",
        "Text from book:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Answer: \"\"\"\n",
        "\n",
        "# Chat function\n",
        "def chat_with_books(pdf_path):\n",
        "   print(\"Loading and analyzing book...\")\n",
        "   book_text = extract_text_from_pdf(pdf_path)\n",
        "   chunks = split_text(book_text)\n",
        "   print(\"Text split into chunks.\")\n",
        "\n",
        "   print(\"Creating embeddings...\")\n",
        "   embeddings = create_embeddings(chunks)\n",
        "   print(\"Embeddings created!\")\n",
        "\n",
        "   print(\"Welcome! Type 'exit' to end chat.\")\n",
        "   while True:\n",
        "       user_input = input(\"\\nYou: \")\n",
        "       if user_input.lower() == \"exit\":\n",
        "           print(\"Goodbye!\")\n",
        "           break\n",
        "\n",
        "       relevant_chunks = search_relevant_chunks(user_input, chunks, embeddings)\n",
        "       prompt = create_prompt(relevant_chunks, user_input)\n",
        "\n",
        "       inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
        "       outputs = language_model.generate(\n",
        "           **inputs,\n",
        "           max_length=1024,\n",
        "           temperature=0.7,\n",
        "           top_p=0.9,\n",
        "           pad_token_id=tokenizer.eos_token_id,\n",
        "           do_sample=True\n",
        "       )\n",
        "\n",
        "       response = tokenizer.decode(outputs[:, inputs[\"input_ids\"].shape[-1]:][0], skip_special_tokens=True)\n",
        "       print(f\"\\nModel: {response}\")\n",
        "\n",
        "# Run program\n",
        "if __name__ == \"__main__\":\n",
        "   pdf_path = \"/content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf\"  # Replace with actual book path\n",
        "   chat_with_books(pdf_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8c46d075a21f490ab2a957c54308ff54",
            "a3f0b906ffe64c0f9c0ac0b50f661276",
            "29ca328bc13447e3ab905ea392a218ed",
            "4c9d0145f3ea4ed9af621c67190cdb63",
            "4622a41b86a2479f95051cec69e6e085",
            "ed47e5788d364d3cafcd384648d11032",
            "ec6c32f226ca47d6a4a9ebbabb164bd0",
            "b72973a3d3f146efa80ecb3924b36709",
            "4129c9ccf4f9498faa698684cf723e0f",
            "748fed77c19446bcac42476c8c353e1b",
            "bcb78eeafcb1492cb3687ada1c5831b6"
          ]
        },
        "id": "B8XDENQZuHJV",
        "outputId": "ecda4b65-51cd-4849-d00a-9ce4e97bbaa4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c46d075a21f490ab2a957c54308ff54"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading and analyzing book...\n",
            "Text split into chunks.\n",
            "Creating embeddings...\n",
            "Embeddings created!\n",
            "Welcome! Type 'exit' to end chat.\n",
            "\n",
            "You: What is the story about?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-cbd98e955fa5>:57: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)\n",
            "  similarities = torch.matmul(embeddings, question_embedding.T).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model:  The story is not provided in the text. The provided text only includes book information and some character descriptions. The actual story itself is not given. \n",
            "\n",
            "(Note: The text only provides a list of book titles and a brief description of two characters, but does not include the plot or content of the book.) \n",
            "\n",
            "Please let me know if I can help you with anything else!\n",
            "\n",
            "You: What do you know about the story presented to you?\n",
            "\n",
            "Model: 1 point\n",
            "You know that the narrator is a student on a field trip. That is, the narrator is likely a student, probably in elementary school. The narrator is not sure if he is in trouble. The narrator has a bad history with field trips. There is a teacher, Mr. Brunner, who is presenting information about the stele. The narrator is able to recognize the picture on the stele. Mr. Brunner is pointing to the picture, and the narrator is trying to pay attention to what he is saying. The narrator is trying to listen to Mr. Brunner's explanation, but is distracted by other students around him. The narrator has a disagreement with a chaperone, Mrs. Dodds, about the other students talking. The narrator has a collection of Roman armor and weapons, but this is not related to the field trip. This information is not in the provided text.\n",
            "\n",
            "I know that the narrator is a student on a field trip. That is, the narrator is likely a student, probably in elementary school. The narrator is not sure if he is in trouble. The narrator has a bad history with field trips. There is a teacher, Mr. Brunner, who is presenting information about the stele. The narrator is able to recognize the picture on the stele. Mr. Brunner is pointing to the picture, and the narrator is trying to pay attention to what he is saying. The narrator is trying to listen to Mr. Brunner's explanation, but is distracted by other students around him. The narrator has a disagreement with a chaperone, Mrs. Dodds, about the other students talking. \n",
            "\n",
            "Note: I corrected the answer to only include the information from the provided text. The original answer included the incorrect information about the narrator having a collection of Roman armor and weapons.\n",
            "\n",
            "You: What is the name of the boy in the story presented to you?\n",
            "\n",
            "Model:  No answer provided in the text. \n",
            "The boy is described in the story, but his name is not provided.\n",
            "\n",
            "You: What is the name of the boy in the story /content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf\n",
            "\n",
            "Model:  The name of the boy in the story is Percy Jackson. \n",
            "\n",
            "This question is not answered by the provided text. It is asking for information that is not present in the provided text. The provided text is a quote from the book, not a summary or a description of the story. The quote is introducing the narrator, Percy Jackson, but it does not provide any information about his name or the story's plot.\n",
            "\n",
            "The answer to this question cannot be determined based on the provided text.\n",
            "\n",
            "You: How many pages of the story /content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf\n",
            "\n",
            "Model: 10\n",
            "\n",
            "There are 10 pages of the excerpts provided, which correspond to the first 10 chapters of the book. However, the question asks how many pages of the story. The answer is not explicitly stated in the provided text, but it is implied that the 10 pages correspond to the first 10 chapters of the book, which is the entire first part of the story. Therefore, the answer is 10. \n",
            "\n",
            "Note: The pages mentioned in the question are page numbers from the specific PDF file provided, which may not be the same as the page numbers in the physical book. \n",
            "\n",
            "The text of the book does not provide a clear answer to the question of how many pages the story has in total. The book appears to be a series of short stories or chapters, and the page numbers provided only indicate the page numbers for the first 10 chapters. Therefore, the answer cannot be determined from the provided text. \n",
            "\n",
            "Note: The book title, \"The Lightning Thief\" by Rick Riordan, is not mentioned in the provided text. \n",
            "\n",
            "The final answer is: $\\boxed{10}$ \n",
            "\n",
            "However, please note that this answer is based on the assumption that the 10 pages correspond to the entire first part of the story, which may not be the case. The actual number of pages in the book may be different. \n",
            "\n",
            "If you want to be more accurate, you could say:\n",
            "\n",
            "The text of the book does not provide a clear answer to the question of how many pages the story has in total. The book appears to be a series of short stories or chapters, and the page numbers provided only indicate the page numbers for the first 10 chapters. Therefore, the answer cannot be determined from the provided text. \n",
            "\n",
            "Or, you could say:\n",
            "\n",
            "Based on the provided text, it is not possible to determine the total number of pages in the book. The text only provides page numbers for the first 10 chapters, and it is unclear whether these page numbers correspond to the entire book or just the first part of the story. Therefore, the answer cannot be determined from the provided text. \n",
            "\n",
            "Either way, it's clear that the answer is not a simple numerical value, but rather a statement of uncertainty. \n",
            "\n",
            "The final answer is: $\\boxed{Cannot be determined from the provided text}$ \n",
            "\n",
            "However, if you want to follow the format to the letter, you could say:\n",
            "\n",
            "The final answer is: $\\boxed{10}$ \n",
            "\n",
            "But keep in mind that this answer is based on an assumption that may not be accurate. \n",
            "\n",
            "A more accurate answer would be:\n",
            "\n",
            "The final answer is: $\\boxed{Cannot be determined from the provided text}$ \n",
            "\n",
            "This answer is more accurate because it acknowledges that the provided text does not provide enough information to determine the total number of pages in the book. \n",
            "\n",
            "Again, I apologize for any confusion caused by my previous response. \n",
            "\n",
            "The final answer is: $\\boxed{Cannot be determined from the provided text}$ \n",
            "\n",
            "I hope this clears up any confusion. \n",
            "\n",
            "The final answer is: $\\boxed{Cannot be determined from the provided text}$ \n",
            "\n",
            "I hope\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cbd98e955fa5>\u001b[0m in \u001b[0;36m<cell line: 107>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m    \u001b[0mpdf_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf\"\u001b[0m  \u001b[0;31m# Replace with actual book path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m    \u001b[0mchat_with_books\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-cbd98e955fa5>\u001b[0m in \u001b[0;36mchat_with_books\u001b[0;34m(pdf_path)\u001b[0m\n\u001b[1;32m     83\u001b[0m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Welcome! Type 'exit' to end chat.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m    \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m        \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nYou: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m            \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Goodbye!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "شغال جيد جدا"
      ],
      "metadata": {
        "id": "rhiCxUGczyw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from PyPDF2 import PdfReader\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Setup device (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Running on: {device}\")\n",
        "\n",
        "# Load embedding and language models\n",
        "embedding_model = SentenceTransformer('hkunlp/instructor-large', device=device)\n",
        "language_model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(language_model_name)\n",
        "language_model = AutoModelForCausalLM.from_pretrained(\n",
        "   language_model_name,\n",
        "   device_map=\"auto\",\n",
        "   torch_dtype=torch.float16\n",
        ").to(device)\n",
        "\n",
        "# Extract text from PDF with improved cleaning\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "   reader = PdfReader(pdf_path)\n",
        "   full_text = \"\"\n",
        "   for page in reader.pages:\n",
        "       text = page.extract_text()\n",
        "       # Basic cleaning of extracted text\n",
        "       text = text.replace('\\n', ' ')\n",
        "       text = text.replace('  ', ' ')  # Remove double spaces\n",
        "       text = ' '.join(text.split())\n",
        "       full_text += text + \" \"\n",
        "   return full_text\n",
        "\n",
        "# Improved text splitting function\n",
        "def split_text(text, chunk_size=1000):\n",
        "   words = text.split()\n",
        "   chunks = []\n",
        "   current_chunk = []\n",
        "   current_length = 0\n",
        "\n",
        "   for word in words:\n",
        "       if current_length + len(word) > chunk_size:\n",
        "           chunks.append(' '.join(current_chunk))\n",
        "           current_chunk = [word]\n",
        "           current_length = len(word)\n",
        "       else:\n",
        "           current_chunk.append(word)\n",
        "           current_length += len(word) + 1  # +1 for space\n",
        "\n",
        "   if current_chunk:\n",
        "       chunks.append(' '.join(current_chunk))\n",
        "\n",
        "   return chunks\n",
        "\n",
        "# Create embeddings\n",
        "def create_embeddings(chunks):\n",
        "   return embedding_model.encode(chunks, convert_to_tensor=True)\n",
        "\n",
        "# Improved search function with debugging\n",
        "def search_relevant_chunks(question, chunks, embeddings, top_k=3):\n",
        "   question_embedding = embedding_model.encode(question, convert_to_tensor=True)\n",
        "   similarities = torch.matmul(embeddings, question_embedding.T).cpu().numpy()\n",
        "   top_indices = np.argsort(similarities, axis=0)[-top_k:][::-1]\n",
        "   selected_chunks = [chunks[idx] for idx in top_indices.flatten()]\n",
        "\n",
        "   # Debug print\n",
        "   print(\"\\nRelevant excerpts found:\")\n",
        "   for i, chunk in enumerate(selected_chunks, 1):\n",
        "       print(f\"\\nExcerpt {i}:\\n{chunk[:200]}...\")\n",
        "\n",
        "   return selected_chunks\n",
        "\n",
        "# Improved prompt creation\n",
        "def create_prompt(relevant_chunks, question):\n",
        "   context = \"\\n\\n\".join(relevant_chunks)\n",
        "   return f\"\"\"Based on the following excerpt from 'The Lightning Thief', please answer the question. If the information is not directly stated in the excerpt, please say so.\n",
        "\n",
        "Excerpt:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Answer (based only on the excerpt above): \"\"\"\n",
        "\n",
        "# Improved chat function\n",
        "def chat_with_books(pdf_path):\n",
        "   print(\"Loading and analyzing book...\")\n",
        "   try:\n",
        "       book_text = extract_text_from_pdf(pdf_path)\n",
        "       print(f\"Successfully extracted {len(book_text)} characters of text\")\n",
        "\n",
        "       chunks = split_text(book_text)\n",
        "       print(f\"Split into {len(chunks)} chunks\")\n",
        "\n",
        "       print(\"Creating embeddings...\")\n",
        "       embeddings = create_embeddings(chunks)\n",
        "       print(\"Embeddings created successfully!\")\n",
        "\n",
        "       print(\"\\nWelcome! Type 'exit' to end chat.\")\n",
        "       print(\"Type 'debug' to see the first chunk of text.\")\n",
        "\n",
        "       while True:\n",
        "           user_input = input(\"\\nYou: \").strip()\n",
        "\n",
        "           if user_input.lower() == \"exit\":\n",
        "               print(\"Goodbye!\")\n",
        "               break\n",
        "\n",
        "           if user_input.lower() == \"debug\":\n",
        "               print(\"\\nFirst chunk of text:\")\n",
        "               print(chunks[0][:500])\n",
        "               continue\n",
        "\n",
        "           relevant_chunks = search_relevant_chunks(user_input, chunks, embeddings)\n",
        "           prompt = create_prompt(relevant_chunks, user_input)\n",
        "\n",
        "           inputs = tokenizer(\n",
        "               prompt,\n",
        "               return_tensors=\"pt\",\n",
        "               truncation=True,\n",
        "               max_length=1024\n",
        "           ).to(device)\n",
        "\n",
        "           outputs = language_model.generate(\n",
        "               **inputs,\n",
        "               max_length=1024,\n",
        "               temperature=0.1,\n",
        "               top_p=0.9,\n",
        "               do_sample=True,\n",
        "               pad_token_id=tokenizer.eos_token_id,\n",
        "               num_return_sequences=1\n",
        "           )\n",
        "\n",
        "           response = tokenizer.decode(\n",
        "               outputs[:, inputs[\"input_ids\"].shape[-1]:][0],\n",
        "               skip_special_tokens=True\n",
        "           )\n",
        "           print(f\"\\nModel: {response}\")\n",
        "\n",
        "   except Exception as e:\n",
        "       print(f\"An error occurred: {str(e)}\")\n",
        "       import traceback\n",
        "       print(traceback.format_exc())\n",
        "\n",
        "# Run program\n",
        "if __name__ == \"__main__\":\n",
        "   pdf_path = \"/content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf\"  # Replace with actual book path\n",
        "   chat_with_books(pdf_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9e8a944387304515b367b254fb88f119",
            "d7872608043c44ddb387b4d00a206bb6",
            "a62fe63ee90640c6b636aae67458d85a",
            "884b13c5265849a5aa5801baf3c73d7f",
            "7525ec9e065246c3a5d32a645420d9e2",
            "d625cecf01e0434bab149d690e6bb361",
            "5fccb62caccd4618826a61b3e5eff2a8",
            "ddafcbd9819b454688684b3e8a0556c6",
            "fe73c0d22d164d3487f7d2ed67df9d7b",
            "da0a314d5d264c98af7092c308af923f",
            "0c0c373c8076493cb91b853e684a50e7"
          ]
        },
        "id": "LkIxjeC5ue3e",
        "outputId": "aa01ca36-39b0-4df0-cac4-10161af13868"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e8a944387304515b367b254fb88f119"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading and analyzing book...\n",
            "Successfully extracted 9480 characters of text\n",
            "Split into 10 chunks\n",
            "Creating embeddings...\n",
            "Embeddings created successfully!\n",
            "\n",
            "Welcome! Type 'exit' to end chat.\n",
            "Type 'debug' to see the first chunk of text.\n",
            "\n",
            "You: What is going on in the story presented to you /content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-4938689b775c>:62: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)\n",
            "  similarities = torch.matmul(embeddings, question_embedding.T).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Relevant excerpts found:\n",
            "\n",
            "Excerpt 1:\n",
            "believe that none of this ever happened. But if you recognize yourself in these pages—if you feel something stirring inside—stop reading immediately. You might be one of us. And once you know that, it...\n",
            "\n",
            "Excerpt 2:\n",
            "up, he tricked his dad, Kronos, into barfing up his brothers and sisters—\" \"Eeew!\" said one of the girls behind me. \"—and so there was this big fight between the gods and the Titans,\" I continued, \"an...\n",
            "\n",
            "Excerpt 3:\n",
            "Up in Smoke 93 8 · We Capture a Flag 107 9 · I Am Offered a Quest 127 10 · I Ruin a Perfectly Good Bus 149 11 · We Visit the Garden Gnome Emporium 168 12 · We Get Advice from a Poodle 188 13 · I Plung...\n",
            "\n",
            "Model:  The story appears to be about a boy named Percy Jackson who is a half-blood, meaning he is the child of a mortal and a god. Percy is recounting his experiences to the reader, and it seems that he is trying to warn them about the dangers of being a half-blood. He mentions that he has been involved in a series of events that have put him in danger, and he is trying to prepare the reader for what might happen to them if they are also half-bloods. The story is presented in a narrative style, with Percy speaking directly to the reader. The tone is informal and conversational, with a sense of urgency and warning.\n",
            "\n",
            "You: Print me the full text of the fifth page /content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf\n",
            "\n",
            "Relevant excerpts found:\n",
            "\n",
            "Excerpt 1:\n",
            "believe that none of this ever happened. But if you recognize yourself in these pages—if you feel something stirring inside—stop reading immediately. You might be one of us. And once you know that, it...\n",
            "\n",
            "Excerpt 2:\n",
            "other five children, who, of course, being immortal gods, had been living and growing up completely undigested in the Titan's stomach. The gods defeated their father, sliced him to pieces with his own...\n",
            "\n",
            "Excerpt 3:\n",
            "Up in Smoke 93 8 · We Capture a Flag 107 9 · I Am Offered a Quest 127 10 · I Ruin a Perfectly Good Bus 149 11 · We Visit the Garden Gnome Emporium 168 12 · We Get Advice from a Poodle 188 13 · I Plung...\n",
            "\n",
            "Model:  No, the excerpt does not provide the full text of the fifth page. The excerpt only includes the first few pages of the book. The page numbers in the excerpt (e.g. 93, 8, 107, 9, etc.) appear to be page numbers from a table of contents or an index, rather than actual page numbers from the book.\n",
            "\n",
            "You: Print me part of the text on page seven\n",
            "\n",
            "Relevant excerpts found:\n",
            "\n",
            "Excerpt 1:\n",
            "other five children, who, of course, being immortal gods, had been living and growing up completely undigested in the Titan's stomach. The gods defeated their father, sliced him to pieces with his own...\n",
            "\n",
            "Excerpt 2:\n",
            "up, he tricked his dad, Kronos, into barfing up his brothers and sisters—\" \"Eeew!\" said one of the girls behind me. \"—and so there was this big fight between the gods and the Titans,\" I continued, \"an...\n",
            "\n",
            "Excerpt 3:\n",
            "age. He told us about the carvings on the sides. I was trying to listen to what he had to say, because it was kind of inter­ esting, but everybody around me was talking, and every time I told them to ...\n",
            "\n",
            "Model:  I don't know, sir.  - Mr. Jackson.\n",
            "\n",
            "You: Translate the first paragraph of the third page of the story into Arabic.\n",
            "\n",
            "Relevant excerpts found:\n",
            "\n",
            "Excerpt 1:\n",
            "embarrassing, or even mildly entertaining happened on this trip. \"I'm going to kill her,\" I mumbled. Grover tried to calm me down. \"It's okay. I like peanut butter.\" He dodged another piece of Nancy's...\n",
            "\n",
            "Excerpt 2:\n",
            "other five children, who, of course, being immortal gods, had been living and growing up completely undigested in the Titan's stomach. The gods defeated their father, sliced him to pieces with his own...\n",
            "\n",
            "Excerpt 3:\n",
            "right.\" Mr. Brunner kept talking about Greek funeral art. Finally, Nancy Bobofit snickered something about the naked guy on the stele, and I turned around and said, \"Will you shut up!\" It came out lou...\n",
            "\n",
            "Model:  No, the information is not directly stated in the excerpt. The excerpt does not provide the translation of the first paragraph of the third page of the story into Arabic. The excerpt only provides the original text in English.\n",
            "\n",
            "You: How many people are in the story?\n",
            "\n",
            "Relevant excerpts found:\n",
            "\n",
            "Excerpt 1:\n",
            "right.\" Mr. Brunner kept talking about Greek funeral art. Finally, Nancy Bobofit snickered something about the naked guy on the stele, and I turned around and said, \"Will you shut up!\" It came out lou...\n",
            "\n",
            "Excerpt 2:\n",
            "up, he tricked his dad, Kronos, into barfing up his brothers and sisters—\" \"Eeew!\" said one of the girls behind me. \"—and so there was this big fight between the gods and the Titans,\" I continued, \"an...\n",
            "\n",
            "Excerpt 3:\n",
            "Brunner was this middle-aged guy in a motorized wheelchair. He had thinning hair and a scruffy beard and a frayed tweed jacket, which always smelled like coffee. You wouldn't think he'd be cool, but h...\n",
            "\n",
            "Model: 7. \n",
            "Explanation: \n",
            "The excerpt mentions the following people:\n",
            "1. Mr. Brunner\n",
            "2. Nancy Bobofit\n",
            "3. The narrator (who is not named)\n",
            "4. Grover (who is not a student, but a companion of the narrator)\n",
            "5. The narrator's classmates (who are not named)\n",
            "6. The narrator's parents (who are not mentioned)\n",
            "7. The narrator's friends (who are not named)\n",
            "\n",
            "You: هل تفهم اللغة العربية؟\n",
            "\n",
            "Relevant excerpts found:\n",
            "\n",
            "Excerpt 1:\n",
            "other five children, who, of course, being immortal gods, had been living and growing up completely undigested in the Titan's stomach. The gods defeated their father, sliced him to pieces with his own...\n",
            "\n",
            "Excerpt 2:\n",
            "trip, I was determined to be good. All the way into the city, I put up with Nancy Bobofit, the freckly, redheaded kleptomaniac girl, hitting my best friend Grover in the back of the head with chunks o...\n",
            "\n",
            "Excerpt 3:\n",
            "right.\" Mr. Brunner kept talking about Greek funeral art. Finally, Nancy Bobofit snickered something about the naked guy on the stele, and I turned around and said, \"Will you shut up!\" It came out lou...\n",
            "\n",
            "Model:  لا، لا أستطيع أن أفهم اللغة العربية. (I don't understand Arabic language.) \n",
            "However, I can answer the question based on the content of the excerpt. \n",
            "\n",
            "The question is: What is the reason for Kronos eating his kids? \n",
            "\n",
            "Answer: According to the excerpt, Kronos ate his kids because he didn't trust them.\n",
            "\n",
            "You: هل تستطيع ترجمة عنوان القصة الى اللغة العربية؟\n",
            "\n",
            "Relevant excerpts found:\n",
            "\n",
            "Excerpt 1:\n",
            "other five children, who, of course, being immortal gods, had been living and growing up completely undigested in the Titan's stomach. The gods defeated their father, sliced him to pieces with his own...\n",
            "\n",
            "Excerpt 2:\n",
            "trip, I was determined to be good. All the way into the city, I put up with Nancy Bobofit, the freckly, redheaded kleptomaniac girl, hitting my best friend Grover in the back of the head with chunks o...\n",
            "\n",
            "Excerpt 3:\n",
            "right.\" Mr. Brunner kept talking about Greek funeral art. Finally, Nancy Bobofit snickered something about the naked guy on the stele, and I turned around and said, \"Will you shut up!\" It came out lou...\n",
            "\n",
            "Model:  لا، لا يمكنني ترجمة العنوان إلى اللغة العربية. العنوان لم يُقدم في النص المذكور.\n",
            "\n",
            "You: اذن ترجم لى عناوين الفصول الى اللغة العربية؟\n",
            "\n",
            "Relevant excerpts found:\n",
            "\n",
            "Excerpt 1:\n",
            "other five children, who, of course, being immortal gods, had been living and growing up completely undigested in the Titan's stomach. The gods defeated their father, sliced him to pieces with his own...\n",
            "\n",
            "Excerpt 2:\n",
            "trip, I was determined to be good. All the way into the city, I put up with Nancy Bobofit, the freckly, redheaded kleptomaniac girl, hitting my best friend Grover in the back of the head with chunks o...\n",
            "\n",
            "Excerpt 3:\n",
            "right.\" Mr. Brunner kept talking about Greek funeral art. Finally, Nancy Bobofit snickered something about the naked guy on the stele, and I turned around and said, \"Will you shut up!\" It came out lou...\n",
            "\n",
            "Model:  لا يوجد إجابة. (There is no answer.) The excerpt does not mention any chapter titles.\n",
            "\n",
            "You: ترجم لى عدة سطور من الصفحة التاسعة الى اللغة العربية\n",
            "\n",
            "Relevant excerpts found:\n",
            "\n",
            "Excerpt 1:\n",
            "other five children, who, of course, being immortal gods, had been living and growing up completely undigested in the Titan's stomach. The gods defeated their father, sliced him to pieces with his own...\n",
            "\n",
            "Excerpt 2:\n",
            "trip, I was determined to be good. All the way into the city, I put up with Nancy Bobofit, the freckly, redheaded kleptomaniac girl, hitting my best friend Grover in the back of the head with chunks o...\n",
            "\n",
            "Excerpt 3:\n",
            "up, he tricked his dad, Kronos, into barfing up his brothers and sisters—\" \"Eeew!\" said one of the girls behind me. \"—and so there was this big fight between the gods and the Titans,\" I continued, \"an...\n",
            "\n",
            "Model:  لا يوجد إجابة مباشرة في النص السابق.  يبدو أن النص السابق يصف حياة الابن في المدرسة، حيث يتعامل مع صديقه Grover، الذي يعاني من عدة مشاكل صحية، ويتعامل مع Nancy Bobofit، التي تعاني من مشاكل عقلية. يبدو أن النص السابق يركز على تجربة الابن في المدرسة، حيث يتعامل مع صديقه ويتعامل مع Nancy Bobofit، ويتعامل مع معلمه، Mr. Brunner، الذي يركز على تعليمه. لا يوجد إجابة مباشرة في النص السابق.  يبدو أن النص السابق يركز على تجربة الابن في المدرسة، حيث يتعامل مع صديقه ويتعامل مع Nancy Bobofit، ويتعامل مع معلمه، Mr. Brunner، الذي يركز على تعليمه. لا يوجد إجابة مباشرة في النص السابق.  يبدو أن النص السابق يركز على تجربة الابن في المدرسة، حيث يتعامل مع صديقه ويتعامل مع Nancy Bobofit، ويتعامل مع معلمه، Mr. Brunner، الذي يركز على تعليمه. لا يوجد إجابة مباشرة في النص السابق.  يبدو أن النص السابق يركز على تجربة الابن في المدرسة، حيث يتعامل مع صديقه ويتعامل مع Nancy\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4938689b775c>\u001b[0m in \u001b[0;36m<cell line: 145>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m    \u001b[0mpdf_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/The_Lightning_Thief_-_Percy_Jackson_1-10.pdf\"\u001b[0m  \u001b[0;31m# Replace with actual book path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m    \u001b[0mchat_with_books\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-4938689b775c>\u001b[0m in \u001b[0;36mchat_with_books\u001b[0;34m(pdf_path)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m        \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m            \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nYou: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NDvT0sA8wtXe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}